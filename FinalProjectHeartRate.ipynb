{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "supreme-feedback",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import random\n",
    "\n",
    "def manipulate0(data, noise_factor):\n",
    "    noise = np.random.randn(len(data))\n",
    "    augmented_data = data + noise_factor * noise\n",
    "    # Cast back to same data type\n",
    "    augmented_data = augmented_data.astype(type(data[0]))\n",
    "    return augmented_data\n",
    "\n",
    "def manipulate1(data, sampling_rate, shift_max, shift_direction):\n",
    "    shift = np.random.randint(sampling_rate * shift_max)\n",
    "    if shift_direction == 'right':\n",
    "        shift = -shift\n",
    "    elif shift_direction == 'both':\n",
    "        direction = np.random.randint(0, 2)\n",
    "        if direction == 1:\n",
    "            shift = -shift\n",
    "    augmented_data = np.roll(data, shift)\n",
    "    # Set to silence for heading/ tailing\n",
    "    if shift > 0:\n",
    "        augmented_data[:shift] = 0\n",
    "    else:\n",
    "        augmented_data[shift:] = 0\n",
    "    return augmented_data\n",
    "\n",
    "def manipulate2(data, sampling_rate, pitch_factor):\n",
    "    return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)\n",
    "\n",
    "def manipulate3(data, speed_factor):\n",
    "    return librosa.effects.time_stretch(data, speed_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "durable-crime",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "97it [04:16,  2.65s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import librosa\n",
    "from librosa.core.convert import mel_frequencies\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import flatten\n",
    "from torch.nn import Conv2d, Linear, LogSoftmax, MaxPool2d, Module, ReLU\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "audio_dataset_path = \"C:/Users/Yashvi/Desktop/TestCases/\"\n",
    "metadata = pd.read_csv(\"C:/Users/Yashvi/Desktop/speech_preprocessing.csv\")\n",
    "metadata.head()\n",
    "\n",
    "kwargs = {\"htk\": True, \"norm\": \"slaney\"}\n",
    "\n",
    "def switch_function(signal,sr):\n",
    "    n = random.randint(0,3)\n",
    "    M0 = [.0050,.0015,.0025,.0060,.0040]\n",
    "    M1 = [0.1,0.2,0.15,0.25,0.3]\n",
    "    M2 = [0.5,1,1.5,2,2.5]\n",
    "    M3 = [0.5,0.75,1,1.15,1.25]\n",
    "    signal={\n",
    "        0: manipulate0(signal,random.choice(M0)),\n",
    "        1: manipulate1(signal,sr,random.choice(M1),'both'),\n",
    "        2: manipulate2(signal,sr,random.choice(M2)),\n",
    "        3: manipulate3(signal,random.choice(M3))\n",
    "    }\n",
    "    return signal.get(n,\"Invalid\")\n",
    "\n",
    "\n",
    "def features_extractor(signal,sr):\n",
    "    preemphasized_signal = librosa.effects.preemphasis(signal, coef=0.95)\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(\n",
    "        y=preemphasized_signal,\n",
    "        sr=44100,\n",
    "        n_mels=42,\n",
    "        n_fft=512,\n",
    "        hop_length=100,\n",
    "        win_length=256,\n",
    "        window=\"hann\",\n",
    "        center=True,\n",
    "        pad_mode=\"reflect\",\n",
    "        power=2.0,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "    mfcc = librosa.feature.mfcc(S=librosa.power_to_db(mel_spectrogram), n_mfcc=12, dct_type=2)\n",
    "    mfcc_scaled_features = np.mean(mfcc.T, axis=0)\n",
    "\n",
    "    return [mfcc_scaled_features, mfcc]\n",
    "\n",
    "\n",
    "\n",
    "extracted_features = []\n",
    "spectogram_data = []\n",
    "for index_num, row in tqdm(metadata.iterrows()):\n",
    "    file_name = os.path.join(os.path.abspath(audio_dataset_path), str(row[\"file_name\"]))\n",
    "    gender_labels = row[\"gender\"]\n",
    "    age_group_labels = row[\"age_group\"]\n",
    "    state_labels = row[\"state\"]\n",
    "    heart_rate_labels = row[\"heart_rate\"]\n",
    "    signal, sr = librosa.load(file_name, sr=44100)\n",
    "    data1 = features_extractor(signal,sr)\n",
    "    signal1 = switch_function(signal,sr)\n",
    "    data2 = features_extractor(signal1,sr)\n",
    "    signal2 = switch_function(signal,sr)\n",
    "    data3 = features_extractor(signal2,sr)\n",
    "    spectogram_data.append(data1[1])\n",
    "    extracted_features.append(\n",
    "        [data1[0], gender_labels, age_group_labels, state_labels, heart_rate_labels]\n",
    "    )\n",
    "    extracted_features.append(\n",
    "        [data2[0], gender_labels, age_group_labels, state_labels, heart_rate_labels]\n",
    "    )\n",
    "    extracted_features.append(\n",
    "        [data3[0], gender_labels, age_group_labels, state_labels, heart_rate_labels]\n",
    "    )\n",
    "\n",
    "one_hot = pd.get_dummies(metadata[\"gender\"])\n",
    "# Drop column B as it is now encoded\n",
    "metadata = metadata.drop(\"gender\", axis=1)\n",
    "# Join the encoded df\n",
    "metadata = metadata.join(one_hot)\n",
    "\n",
    "newstates= []\n",
    "states = metadata[\"state\"].to_list()\n",
    "for state in states:\n",
    "    newstates.append(\n",
    "        state.lower().strip()\n",
    "    )\n",
    "metadata = metadata.drop(\"state\", axis=1)\n",
    "metadata['state'] = newstates\n",
    "\n",
    "one_hot = pd.get_dummies(metadata[\"state\"])\n",
    "metadata = metadata.drop(\"state\", axis=1)\n",
    "metadata = metadata.join(one_hot)\n",
    "\n",
    "one_hot = pd.get_dummies(metadata[\"age_group\"])\n",
    "metadata = metadata.drop(\"age_group\", axis=1)\n",
    "metadata = metadata.join(one_hot)\n",
    "\n",
    "heart_rates = metadata[\"heart_rate\"].to_list()\n",
    "\n",
    "metadata = metadata.drop(\"heart_rate\", axis=1)\n",
    "metadata = metadata.drop(\"file_name\", axis=1)\n",
    "\n",
    "\n",
    "remaining_features = metadata.values\n",
    "\n",
    "result = []\n",
    "\n",
    "for i in range(len(extracted_features)):\n",
    "    features = extracted_features[i][0].tolist()\n",
    "    new = []\n",
    "\n",
    "    new += extracted_features[i][0].tolist()\n",
    "    new += remaining_features[i%97].tolist()\n",
    "    new.append(heart_rates[i%97])\n",
    "\n",
    "    result.append(new)\n",
    "\n",
    "names = []\n",
    "for i in range(1,13):\n",
    "    names.append(f\"mfcc_{i}\")\n",
    "s = \"F \tM \tafter_workout \thappy \tneutral \trelaxed \tstressed \ttired \t20-29 \t30-39 \t40-49 \t50-59 \t60-69\"\n",
    "\n",
    "names = names + s.strip().split()\n",
    "names.append(\"heart_rate\")\n",
    "\n",
    "pd.DataFrame(result, columns=names).to_csv(\"save.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "liquid-muslim",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-424.3054   ,   28.069408 ,   -0.9381784,   34.194496 ,\n",
      "        -15.37882  ,   13.257497 ,  -15.704871 ,    3.3506052,\n",
      "         -6.0990524,    2.1145062,    3.0280347,   -6.034267 ],\n",
      "      dtype=float32), 'F', '20-29', 'tired', 80]\n",
      "[1 0 0 0 0 0 0 1 1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(extracted_features[0])\n",
    "print(remaining_features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "helpful-transportation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F</th>\n",
       "      <th>M</th>\n",
       "      <th>after_workout</th>\n",
       "      <th>happy</th>\n",
       "      <th>neutral</th>\n",
       "      <th>relaxed</th>\n",
       "      <th>stressed</th>\n",
       "      <th>tired</th>\n",
       "      <th>20-29</th>\n",
       "      <th>30-39</th>\n",
       "      <th>40-49</th>\n",
       "      <th>50-59</th>\n",
       "      <th>60-69</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   F  M  after_workout  happy  neutral  relaxed  stressed  tired  20-29  \\\n",
       "0  1  0              0      0        0        0         0      1      1   \n",
       "1  0  1              0      0        0        0         0      1      1   \n",
       "2  0  1              1      0        0        0         0      0      1   \n",
       "3  1  0              0      0        0        0         0      1      1   \n",
       "4  0  1              0      1        0        0         0      0      1   \n",
       "\n",
       "   30-39  40-49  50-59  60-69  \n",
       "0      0      0      0      0  \n",
       "1      0      0      0      0  \n",
       "2      0      0      0      0  \n",
       "3      0      0      0      0  \n",
       "4      0      0      0      0  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "nonprofit-import",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training the network...\n",
      "[INFO] EPOCH: 1/1000\n",
      "Train loss: 7770.501953\n",
      "Test loss: 7753.899273\n",
      "\n",
      "[INFO] EPOCH: 2/1000\n",
      "Train loss: 7634.820801\n",
      "Test loss: 7604.985752\n",
      "\n",
      "[INFO] EPOCH: 3/1000\n",
      "Train loss: 7573.990723\n",
      "Test loss: 7455.704735\n",
      "\n",
      "[INFO] EPOCH: 4/1000\n",
      "Train loss: 7398.588867\n",
      "Test loss: 7312.229932\n",
      "\n",
      "[INFO] EPOCH: 5/1000\n",
      "Train loss: 7144.687988\n",
      "Test loss: 7168.286338\n",
      "\n",
      "[INFO] EPOCH: 6/1000\n",
      "Train loss: 7230.029785\n",
      "Test loss: 7028.167567\n",
      "\n",
      "[INFO] EPOCH: 7/1000\n",
      "Train loss: 7031.935547\n",
      "Test loss: 6889.491442\n",
      "\n",
      "[INFO] EPOCH: 8/1000\n",
      "Train loss: 6997.109863\n",
      "Test loss: 6750.193522\n",
      "\n",
      "[INFO] EPOCH: 9/1000\n",
      "Train loss: 6797.010742\n",
      "Test loss: 6614.286667\n",
      "\n",
      "[INFO] EPOCH: 10/1000\n",
      "Train loss: 6751.740723\n",
      "Test loss: 6478.309097\n",
      "\n",
      "[INFO] EPOCH: 11/1000\n",
      "Train loss: 6599.065430\n",
      "Test loss: 6343.974789\n",
      "\n",
      "[INFO] EPOCH: 12/1000\n",
      "Train loss: 6574.500000\n",
      "Test loss: 6211.440276\n",
      "\n",
      "[INFO] EPOCH: 13/1000\n",
      "Train loss: 6352.411133\n",
      "Test loss: 6080.447947\n",
      "\n",
      "[INFO] EPOCH: 14/1000\n",
      "Train loss: 6128.214844\n",
      "Test loss: 5946.958857\n",
      "\n",
      "[INFO] EPOCH: 15/1000\n",
      "Train loss: 6018.566406\n",
      "Test loss: 5816.194353\n",
      "\n",
      "[INFO] EPOCH: 16/1000\n",
      "Train loss: 5998.907715\n",
      "Test loss: 5686.592022\n",
      "\n",
      "[INFO] EPOCH: 17/1000\n",
      "Train loss: 5709.421875\n",
      "Test loss: 5558.000828\n",
      "\n",
      "[INFO] EPOCH: 18/1000\n",
      "Train loss: 5613.351074\n",
      "Test loss: 5429.784158\n",
      "\n",
      "[INFO] EPOCH: 19/1000\n",
      "Train loss: 5607.255859\n",
      "Test loss: 5302.875298\n",
      "\n",
      "[INFO] EPOCH: 20/1000\n",
      "Train loss: 5357.493164\n",
      "Test loss: 5175.746699\n",
      "\n",
      "[INFO] EPOCH: 21/1000\n",
      "Train loss: 5291.251465\n",
      "Test loss: 5049.670061\n",
      "\n",
      "[INFO] EPOCH: 22/1000\n",
      "Train loss: 5196.725098\n",
      "Test loss: 4925.870546\n",
      "\n",
      "[INFO] EPOCH: 23/1000\n",
      "Train loss: 5039.881836\n",
      "Test loss: 4804.055425\n",
      "\n",
      "[INFO] EPOCH: 24/1000\n",
      "Train loss: 4930.059570\n",
      "Test loss: 4680.699980\n",
      "\n",
      "[INFO] EPOCH: 25/1000\n",
      "Train loss: 4837.562012\n",
      "Test loss: 4556.846293\n",
      "\n",
      "[INFO] EPOCH: 26/1000\n",
      "Train loss: 4881.135742\n",
      "Test loss: 4435.441293\n",
      "\n",
      "[INFO] EPOCH: 27/1000\n",
      "Train loss: 4632.294922\n",
      "Test loss: 4314.548106\n",
      "\n",
      "[INFO] EPOCH: 28/1000\n",
      "Train loss: 4398.253418\n",
      "Test loss: 4194.987411\n",
      "\n",
      "[INFO] EPOCH: 29/1000\n",
      "Train loss: 4339.190918\n",
      "Test loss: 4077.439351\n",
      "\n",
      "[INFO] EPOCH: 30/1000\n",
      "Train loss: 4324.767090\n",
      "Test loss: 3960.068253\n",
      "\n",
      "[INFO] EPOCH: 31/1000\n",
      "Train loss: 4270.507324\n",
      "Test loss: 3844.515092\n",
      "\n",
      "[INFO] EPOCH: 32/1000\n",
      "Train loss: 3985.464600\n",
      "Test loss: 3727.176747\n",
      "\n",
      "[INFO] EPOCH: 33/1000\n",
      "Train loss: 3905.056152\n",
      "Test loss: 3614.018485\n",
      "\n",
      "[INFO] EPOCH: 34/1000\n",
      "Train loss: 3794.920166\n",
      "Test loss: 3503.532121\n",
      "\n",
      "[INFO] EPOCH: 35/1000\n",
      "Train loss: 3820.897461\n",
      "Test loss: 3393.794488\n",
      "\n",
      "[INFO] EPOCH: 36/1000\n",
      "Train loss: 3700.765381\n",
      "Test loss: 3284.687796\n",
      "\n",
      "[INFO] EPOCH: 37/1000\n",
      "Train loss: 3690.583984\n",
      "Test loss: 3176.514375\n",
      "\n",
      "[INFO] EPOCH: 38/1000\n",
      "Train loss: 3376.589111\n",
      "Test loss: 3069.066143\n",
      "\n",
      "[INFO] EPOCH: 39/1000\n",
      "Train loss: 3395.190186\n",
      "Test loss: 2963.959588\n",
      "\n",
      "[INFO] EPOCH: 40/1000\n",
      "Train loss: 3255.905273\n",
      "Test loss: 2860.264159\n",
      "\n",
      "[INFO] EPOCH: 41/1000\n",
      "Train loss: 3259.604004\n",
      "Test loss: 2756.448644\n",
      "\n",
      "[INFO] EPOCH: 42/1000\n",
      "Train loss: 3015.675293\n",
      "Test loss: 2653.414871\n",
      "\n",
      "[INFO] EPOCH: 43/1000\n",
      "Train loss: 2976.573486\n",
      "Test loss: 2553.707392\n",
      "\n",
      "[INFO] EPOCH: 44/1000\n",
      "Train loss: 2921.329590\n",
      "Test loss: 2454.447414\n",
      "\n",
      "[INFO] EPOCH: 45/1000\n",
      "Train loss: 2783.222168\n",
      "Test loss: 2355.222746\n",
      "\n",
      "[INFO] EPOCH: 46/1000\n",
      "Train loss: 2745.792725\n",
      "Test loss: 2257.913816\n",
      "\n",
      "[INFO] EPOCH: 47/1000\n",
      "Train loss: 2677.875244\n",
      "Test loss: 2162.791786\n",
      "\n",
      "[INFO] EPOCH: 48/1000\n",
      "Train loss: 2623.989746\n",
      "Test loss: 2069.328021\n",
      "\n",
      "[INFO] EPOCH: 49/1000\n",
      "Train loss: 2422.381348\n",
      "Test loss: 1974.065743\n",
      "\n",
      "[INFO] EPOCH: 50/1000\n",
      "Train loss: 2354.008789\n",
      "Test loss: 1882.940681\n",
      "\n",
      "[INFO] EPOCH: 51/1000\n",
      "Train loss: 2345.162598\n",
      "Test loss: 1794.728026\n",
      "\n",
      "[INFO] EPOCH: 52/1000\n",
      "Train loss: 2270.003662\n",
      "Test loss: 1707.722522\n",
      "\n",
      "[INFO] EPOCH: 53/1000\n",
      "Train loss: 2098.621338\n",
      "Test loss: 1622.815302\n",
      "\n",
      "[INFO] EPOCH: 54/1000\n",
      "Train loss: 2056.362549\n",
      "Test loss: 1541.492372\n",
      "\n",
      "[INFO] EPOCH: 55/1000\n",
      "Train loss: 1966.304810\n",
      "Test loss: 1461.553507\n",
      "\n",
      "[INFO] EPOCH: 56/1000\n",
      "Train loss: 1928.889282\n",
      "Test loss: 1383.761371\n",
      "\n",
      "[INFO] EPOCH: 57/1000\n",
      "Train loss: 1858.380615\n",
      "Test loss: 1309.466088\n",
      "\n",
      "[INFO] EPOCH: 58/1000\n",
      "Train loss: 1626.024780\n",
      "Test loss: 1237.017830\n",
      "\n",
      "[INFO] EPOCH: 59/1000\n",
      "Train loss: 1749.413086\n",
      "Test loss: 1169.994813\n",
      "\n",
      "[INFO] EPOCH: 60/1000\n",
      "Train loss: 1615.081299\n",
      "Test loss: 1103.346747\n",
      "\n",
      "[INFO] EPOCH: 61/1000\n",
      "Train loss: 1556.546997\n",
      "Test loss: 1039.787372\n",
      "\n",
      "[INFO] EPOCH: 62/1000\n",
      "Train loss: 1450.610229\n",
      "Test loss: 978.119791\n",
      "\n",
      "[INFO] EPOCH: 63/1000\n",
      "Train loss: 1418.337036\n",
      "Test loss: 920.429357\n",
      "\n",
      "[INFO] EPOCH: 64/1000\n",
      "Train loss: 1441.422852\n",
      "Test loss: 865.375058\n",
      "\n",
      "[INFO] EPOCH: 65/1000\n",
      "Train loss: 1296.423218\n",
      "Test loss: 811.283522\n",
      "\n",
      "[INFO] EPOCH: 66/1000\n",
      "Train loss: 1227.693481\n",
      "Test loss: 761.196712\n",
      "\n",
      "[INFO] EPOCH: 67/1000\n",
      "Train loss: 1184.710693\n",
      "Test loss: 714.806888\n",
      "\n",
      "[INFO] EPOCH: 68/1000\n",
      "Train loss: 1142.668945\n",
      "Test loss: 670.310573\n",
      "\n",
      "[INFO] EPOCH: 69/1000\n",
      "Train loss: 1106.053589\n",
      "Test loss: 629.072010\n",
      "\n",
      "[INFO] EPOCH: 70/1000\n",
      "Train loss: 1075.139160\n",
      "Test loss: 588.642612\n",
      "\n",
      "[INFO] EPOCH: 71/1000\n",
      "Train loss: 1005.365906\n",
      "Test loss: 551.234683\n",
      "\n",
      "[INFO] EPOCH: 72/1000\n",
      "Train loss: 953.377319\n",
      "Test loss: 517.685577\n",
      "\n",
      "[INFO] EPOCH: 73/1000\n",
      "Train loss: 926.369507\n",
      "Test loss: 485.844812\n",
      "\n",
      "[INFO] EPOCH: 74/1000\n",
      "Train loss: 858.228027\n",
      "Test loss: 457.517268\n",
      "\n",
      "[INFO] EPOCH: 75/1000\n",
      "Train loss: 828.569824\n",
      "Test loss: 430.553759\n",
      "\n",
      "[INFO] EPOCH: 76/1000\n",
      "Train loss: 821.049194\n",
      "Test loss: 405.772005\n",
      "\n",
      "[INFO] EPOCH: 77/1000\n",
      "Train loss: 803.951965\n",
      "Test loss: 382.618157\n",
      "\n",
      "[INFO] EPOCH: 78/1000\n",
      "Train loss: 731.779114\n",
      "Test loss: 362.169541\n",
      "\n",
      "[INFO] EPOCH: 79/1000\n",
      "Train loss: 721.576843\n",
      "Test loss: 342.770841\n",
      "\n",
      "[INFO] EPOCH: 80/1000\n",
      "Train loss: 648.467834\n",
      "Test loss: 327.196248\n",
      "\n",
      "[INFO] EPOCH: 81/1000\n",
      "Train loss: 632.428345\n",
      "Test loss: 312.369233\n",
      "\n",
      "[INFO] EPOCH: 82/1000\n",
      "Train loss: 679.583191\n",
      "Test loss: 298.411421\n",
      "\n",
      "[INFO] EPOCH: 83/1000\n",
      "Train loss: 658.530884\n",
      "Test loss: 286.031904\n",
      "\n",
      "[INFO] EPOCH: 84/1000\n",
      "Train loss: 636.149536\n",
      "Test loss: 275.339000\n",
      "\n",
      "[INFO] EPOCH: 85/1000\n",
      "Train loss: 660.556519\n",
      "Test loss: 266.370303\n",
      "\n",
      "[INFO] EPOCH: 86/1000\n",
      "Train loss: 613.979065\n",
      "Test loss: 257.770144\n",
      "\n",
      "[INFO] EPOCH: 87/1000\n",
      "Train loss: 542.884338\n",
      "Test loss: 251.299230\n",
      "\n",
      "[INFO] EPOCH: 88/1000\n",
      "Train loss: 535.925171\n",
      "Test loss: 246.111612\n",
      "\n",
      "[INFO] EPOCH: 89/1000\n",
      "Train loss: 568.424255\n",
      "Test loss: 241.945610\n",
      "\n",
      "[INFO] EPOCH: 90/1000\n",
      "Train loss: 530.978027\n",
      "Test loss: 238.124144\n",
      "\n",
      "[INFO] EPOCH: 91/1000\n",
      "Train loss: 536.133972\n",
      "Test loss: 235.170352\n",
      "\n",
      "[INFO] EPOCH: 92/1000\n",
      "Train loss: 471.932861\n",
      "Test loss: 233.475243\n",
      "\n",
      "[INFO] EPOCH: 93/1000\n",
      "Train loss: 531.781372\n",
      "Test loss: 232.191637\n",
      "\n",
      "[INFO] EPOCH: 94/1000\n",
      "Train loss: 468.764404\n",
      "Test loss: 231.600532\n",
      "\n",
      "[INFO] EPOCH: 95/1000\n",
      "Train loss: 508.897156\n",
      "Test loss: 231.607167\n",
      "\n",
      "[INFO] EPOCH: 96/1000\n",
      "Train loss: 535.586182\n",
      "Test loss: 232.258662\n",
      "\n",
      "[INFO] EPOCH: 97/1000\n",
      "Train loss: 489.816528\n",
      "Test loss: 233.352991\n",
      "\n",
      "[INFO] EPOCH: 98/1000\n",
      "Train loss: 485.095520\n",
      "Test loss: 234.913840\n",
      "\n",
      "[INFO] EPOCH: 99/1000\n",
      "Train loss: 463.263153\n",
      "Test loss: 236.508737\n",
      "\n",
      "[INFO] EPOCH: 100/1000\n",
      "Train loss: 458.148010\n",
      "Test loss: 238.029405\n",
      "\n",
      "[INFO] EPOCH: 101/1000\n",
      "Train loss: 440.565979\n",
      "Test loss: 240.244529\n",
      "\n",
      "[INFO] EPOCH: 102/1000\n",
      "Train loss: 464.936707\n",
      "Test loss: 242.866152\n",
      "\n",
      "[INFO] EPOCH: 103/1000\n",
      "Train loss: 426.231018\n",
      "Test loss: 244.953322\n",
      "\n",
      "[INFO] EPOCH: 104/1000\n",
      "Train loss: 451.881714\n",
      "Test loss: 246.811349\n",
      "\n",
      "[INFO] EPOCH: 105/1000\n",
      "Train loss: 430.474182\n",
      "Test loss: 248.265588\n",
      "\n",
      "[INFO] EPOCH: 106/1000\n",
      "Train loss: 423.395721\n",
      "Test loss: 249.804074\n",
      "\n",
      "[INFO] EPOCH: 107/1000\n",
      "Train loss: 457.750732\n",
      "Test loss: 250.994705\n",
      "\n",
      "[INFO] EPOCH: 108/1000\n",
      "Train loss: 457.970276\n",
      "Test loss: 253.787407\n",
      "\n",
      "[INFO] EPOCH: 109/1000\n",
      "Train loss: 409.279755\n",
      "Test loss: 255.984890\n",
      "\n",
      "[INFO] EPOCH: 110/1000\n",
      "Train loss: 422.216705\n",
      "Test loss: 256.508645\n",
      "\n",
      "[INFO] EPOCH: 111/1000\n",
      "Train loss: 454.347107\n",
      "Test loss: 258.330325\n",
      "\n",
      "[INFO] EPOCH: 112/1000\n",
      "Train loss: 399.785889\n",
      "Test loss: 260.437921\n",
      "\n",
      "[INFO] EPOCH: 113/1000\n",
      "Train loss: 418.278839\n",
      "Test loss: 261.601718\n",
      "\n",
      "[INFO] EPOCH: 114/1000\n",
      "Train loss: 407.304443\n",
      "Test loss: 264.371820\n",
      "\n",
      "[INFO] EPOCH: 115/1000\n",
      "Train loss: 436.914825\n",
      "Test loss: 267.289767\n",
      "\n",
      "[INFO] EPOCH: 116/1000\n",
      "Train loss: 436.581177\n",
      "Test loss: 269.108072\n",
      "\n",
      "[INFO] EPOCH: 117/1000\n",
      "Train loss: 399.445221\n",
      "Test loss: 269.829627\n",
      "\n",
      "[INFO] EPOCH: 118/1000\n",
      "Train loss: 443.837494\n",
      "Test loss: 268.975762\n",
      "\n",
      "[INFO] EPOCH: 119/1000\n",
      "Train loss: 449.869568\n",
      "Test loss: 270.734120\n",
      "\n",
      "[INFO] EPOCH: 120/1000\n",
      "Train loss: 408.871857\n",
      "Test loss: 271.590183\n",
      "\n",
      "[INFO] EPOCH: 121/1000\n",
      "Train loss: 422.140411\n",
      "Test loss: 272.448457\n",
      "\n",
      "[INFO] EPOCH: 122/1000\n",
      "Train loss: 406.288483\n",
      "Test loss: 272.996731\n",
      "\n",
      "[INFO] EPOCH: 123/1000\n",
      "Train loss: 429.653717\n",
      "Test loss: 272.933608\n",
      "\n",
      "[INFO] EPOCH: 124/1000\n",
      "Train loss: 414.829865\n",
      "Test loss: 274.301467\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] EPOCH: 125/1000\n",
      "Train loss: 373.403564\n",
      "Test loss: 275.050999\n",
      "\n",
      "[INFO] EPOCH: 126/1000\n",
      "Train loss: 429.442719\n",
      "Test loss: 275.721695\n",
      "\n",
      "[INFO] EPOCH: 127/1000\n",
      "Train loss: 441.657745\n",
      "Test loss: 276.043238\n",
      "\n",
      "[INFO] EPOCH: 128/1000\n",
      "Train loss: 442.676544\n",
      "Test loss: 276.460522\n",
      "\n",
      "[INFO] EPOCH: 129/1000\n",
      "Train loss: 441.080292\n",
      "Test loss: 278.391325\n",
      "\n",
      "[INFO] EPOCH: 130/1000\n",
      "Train loss: 402.909973\n",
      "Test loss: 277.073005\n",
      "\n",
      "[INFO] EPOCH: 131/1000\n",
      "Train loss: 402.236877\n",
      "Test loss: 276.225263\n",
      "\n",
      "[INFO] EPOCH: 132/1000\n",
      "Train loss: 428.996979\n",
      "Test loss: 277.748851\n",
      "\n",
      "[INFO] EPOCH: 133/1000\n",
      "Train loss: 433.479309\n",
      "Test loss: 280.343580\n",
      "\n",
      "[INFO] EPOCH: 134/1000\n",
      "Train loss: 434.452332\n",
      "Test loss: 281.579165\n",
      "\n",
      "[INFO] EPOCH: 135/1000\n",
      "Train loss: 397.002197\n",
      "Test loss: 282.183731\n",
      "\n",
      "[INFO] EPOCH: 136/1000\n",
      "Train loss: 447.361237\n",
      "Test loss: 280.477152\n",
      "\n",
      "[INFO] EPOCH: 137/1000\n",
      "Train loss: 444.902740\n",
      "Test loss: 281.304896\n",
      "\n",
      "[INFO] EPOCH: 138/1000\n",
      "Train loss: 438.492004\n",
      "Test loss: 281.715890\n",
      "\n",
      "[INFO] EPOCH: 139/1000\n",
      "Train loss: 360.987610\n",
      "Test loss: 279.559891\n",
      "\n",
      "[INFO] EPOCH: 140/1000\n",
      "Train loss: 415.499023\n",
      "Test loss: 281.680670\n",
      "\n",
      "[INFO] EPOCH: 141/1000\n",
      "Train loss: 395.009186\n",
      "Test loss: 282.056369\n",
      "\n",
      "[INFO] EPOCH: 142/1000\n",
      "Train loss: 436.239594\n",
      "Test loss: 282.642367\n",
      "\n",
      "[INFO] EPOCH: 143/1000\n",
      "Train loss: 450.631653\n",
      "Test loss: 282.112730\n",
      "\n",
      "[INFO] EPOCH: 144/1000\n",
      "Train loss: 444.304932\n",
      "Test loss: 280.380206\n",
      "\n",
      "[INFO] EPOCH: 145/1000\n",
      "Train loss: 394.023132\n",
      "Test loss: 278.269916\n",
      "\n",
      "[INFO] EPOCH: 146/1000\n",
      "Train loss: 372.023315\n",
      "Test loss: 275.144628\n",
      "\n",
      "[INFO] EPOCH: 147/1000\n",
      "Train loss: 426.870850\n",
      "Test loss: 274.409245\n",
      "\n",
      "[INFO] EPOCH: 148/1000\n",
      "Train loss: 386.901398\n",
      "Test loss: 272.283674\n",
      "\n",
      "[INFO] EPOCH: 149/1000\n",
      "Train loss: 439.616241\n",
      "Test loss: 272.580999\n",
      "\n",
      "[INFO] EPOCH: 150/1000\n",
      "Train loss: 389.554504\n",
      "Test loss: 270.972967\n",
      "\n",
      "[INFO] EPOCH: 151/1000\n",
      "Train loss: 425.199890\n",
      "Test loss: 271.235022\n",
      "\n",
      "[INFO] EPOCH: 152/1000\n",
      "Train loss: 416.681610\n",
      "Test loss: 267.506828\n",
      "\n",
      "[INFO] EPOCH: 153/1000\n",
      "Train loss: 375.440765\n",
      "Test loss: 267.998552\n",
      "\n",
      "[INFO] EPOCH: 154/1000\n",
      "Train loss: 424.944977\n",
      "Test loss: 268.732563\n",
      "\n",
      "[INFO] EPOCH: 155/1000\n",
      "Train loss: 400.884247\n",
      "Test loss: 264.186253\n",
      "\n",
      "[INFO] EPOCH: 156/1000\n",
      "Train loss: 404.167236\n",
      "Test loss: 265.240052\n",
      "\n",
      "[INFO] EPOCH: 157/1000\n",
      "Train loss: 401.439911\n",
      "Test loss: 265.358076\n",
      "\n",
      "[INFO] EPOCH: 158/1000\n",
      "Train loss: 390.804047\n",
      "Test loss: 265.181147\n",
      "\n",
      "[INFO] EPOCH: 159/1000\n",
      "Train loss: 350.063232\n",
      "Test loss: 265.287574\n",
      "\n",
      "[INFO] EPOCH: 160/1000\n",
      "Train loss: 415.048645\n",
      "Test loss: 266.129952\n",
      "\n",
      "[INFO] EPOCH: 161/1000\n",
      "Train loss: 396.492157\n",
      "Test loss: 263.431355\n",
      "\n",
      "[INFO] EPOCH: 162/1000\n",
      "Train loss: 409.817902\n",
      "Test loss: 263.306674\n",
      "\n",
      "[INFO] EPOCH: 163/1000\n",
      "Train loss: 390.460541\n",
      "Test loss: 263.245419\n",
      "\n",
      "[INFO] EPOCH: 164/1000\n",
      "Train loss: 371.632629\n",
      "Test loss: 263.019557\n",
      "\n",
      "[INFO] EPOCH: 165/1000\n",
      "Train loss: 422.438477\n",
      "Test loss: 260.344601\n",
      "\n",
      "[INFO] EPOCH: 166/1000\n",
      "Train loss: 376.648468\n",
      "Test loss: 257.268501\n",
      "\n",
      "[INFO] EPOCH: 167/1000\n",
      "Train loss: 402.203156\n",
      "Test loss: 256.443500\n",
      "\n",
      "[INFO] EPOCH: 168/1000\n",
      "Train loss: 388.817932\n",
      "Test loss: 257.919147\n",
      "\n",
      "[INFO] EPOCH: 169/1000\n",
      "Train loss: 408.953094\n",
      "Test loss: 260.509333\n",
      "\n",
      "[INFO] EPOCH: 170/1000\n",
      "Train loss: 389.049286\n",
      "Test loss: 261.173763\n",
      "\n",
      "[INFO] EPOCH: 171/1000\n",
      "Train loss: 351.448273\n",
      "Test loss: 262.822892\n",
      "\n",
      "[INFO] EPOCH: 172/1000\n",
      "Train loss: 387.312073\n",
      "Test loss: 264.632327\n",
      "\n",
      "[INFO] EPOCH: 173/1000\n",
      "Train loss: 396.435333\n",
      "Test loss: 264.624986\n",
      "\n",
      "[INFO] EPOCH: 174/1000\n",
      "Train loss: 413.940674\n",
      "Test loss: 264.223335\n",
      "\n",
      "[INFO] EPOCH: 175/1000\n",
      "Train loss: 400.122040\n",
      "Test loss: 263.247306\n",
      "\n",
      "[INFO] EPOCH: 176/1000\n",
      "Train loss: 386.413849\n",
      "Test loss: 259.739722\n",
      "\n",
      "[INFO] EPOCH: 177/1000\n",
      "Train loss: 372.401672\n",
      "Test loss: 257.498986\n",
      "\n",
      "[INFO] EPOCH: 178/1000\n",
      "Train loss: 383.575958\n",
      "Test loss: 255.431364\n",
      "\n",
      "[INFO] EPOCH: 179/1000\n",
      "Train loss: 393.183258\n",
      "Test loss: 256.680070\n",
      "\n",
      "[INFO] EPOCH: 180/1000\n",
      "Train loss: 397.061066\n",
      "Test loss: 255.651047\n",
      "\n",
      "[INFO] EPOCH: 181/1000\n",
      "Train loss: 388.173035\n",
      "Test loss: 254.452556\n",
      "\n",
      "[INFO] EPOCH: 182/1000\n",
      "Train loss: 411.026367\n",
      "Test loss: 252.872398\n",
      "\n",
      "[INFO] EPOCH: 183/1000\n",
      "Train loss: 383.051941\n",
      "Test loss: 253.628015\n",
      "\n",
      "[INFO] EPOCH: 184/1000\n",
      "Train loss: 430.170380\n",
      "Test loss: 250.198264\n",
      "\n",
      "[INFO] EPOCH: 185/1000\n",
      "Train loss: 431.642395\n",
      "Test loss: 251.684771\n",
      "\n",
      "[INFO] EPOCH: 186/1000\n",
      "Train loss: 424.345154\n",
      "Test loss: 251.239824\n",
      "\n",
      "[INFO] EPOCH: 187/1000\n",
      "Train loss: 357.537872\n",
      "Test loss: 250.455035\n",
      "\n",
      "[INFO] EPOCH: 188/1000\n",
      "Train loss: 357.364594\n",
      "Test loss: 252.383268\n",
      "\n",
      "[INFO] EPOCH: 189/1000\n",
      "Train loss: 389.469543\n",
      "Test loss: 252.233049\n",
      "\n",
      "[INFO] EPOCH: 190/1000\n",
      "Train loss: 368.191223\n",
      "Test loss: 249.998618\n",
      "\n",
      "[INFO] EPOCH: 191/1000\n",
      "Train loss: 399.286469\n",
      "Test loss: 248.618901\n",
      "\n",
      "[INFO] EPOCH: 192/1000\n",
      "Train loss: 390.072296\n",
      "Test loss: 245.530481\n",
      "\n",
      "[INFO] EPOCH: 193/1000\n",
      "Train loss: 368.596680\n",
      "Test loss: 243.338383\n",
      "\n",
      "[INFO] EPOCH: 194/1000\n",
      "Train loss: 381.919678\n",
      "Test loss: 243.668959\n",
      "\n",
      "[INFO] EPOCH: 195/1000\n",
      "Train loss: 361.737518\n",
      "Test loss: 244.383008\n",
      "\n",
      "[INFO] EPOCH: 196/1000\n",
      "Train loss: 391.981323\n",
      "Test loss: 245.170100\n",
      "\n",
      "[INFO] EPOCH: 197/1000\n",
      "Train loss: 350.416321\n",
      "Test loss: 244.421708\n",
      "\n",
      "[INFO] EPOCH: 198/1000\n",
      "Train loss: 383.661163\n",
      "Test loss: 244.562272\n",
      "\n",
      "[INFO] EPOCH: 199/1000\n",
      "Train loss: 369.448242\n",
      "Test loss: 242.367636\n",
      "\n",
      "[INFO] EPOCH: 200/1000\n",
      "Train loss: 381.641144\n",
      "Test loss: 242.540637\n",
      "\n",
      "[INFO] EPOCH: 201/1000\n",
      "Train loss: 360.577332\n",
      "Test loss: 244.508350\n",
      "\n",
      "[INFO] EPOCH: 202/1000\n",
      "Train loss: 380.222198\n",
      "Test loss: 244.064632\n",
      "\n",
      "[INFO] EPOCH: 203/1000\n",
      "Train loss: 401.954742\n",
      "Test loss: 244.517550\n",
      "\n",
      "[INFO] EPOCH: 204/1000\n",
      "Train loss: 400.280273\n",
      "Test loss: 245.472436\n",
      "\n",
      "[INFO] EPOCH: 205/1000\n",
      "Train loss: 395.216583\n",
      "Test loss: 244.155394\n",
      "\n",
      "[INFO] EPOCH: 206/1000\n",
      "Train loss: 392.829132\n",
      "Test loss: 240.886093\n",
      "\n",
      "[INFO] EPOCH: 207/1000\n",
      "Train loss: 375.590057\n",
      "Test loss: 241.202226\n",
      "\n",
      "[INFO] EPOCH: 208/1000\n",
      "Train loss: 420.022339\n",
      "Test loss: 239.772424\n",
      "\n",
      "[INFO] EPOCH: 209/1000\n",
      "Train loss: 359.342682\n",
      "Test loss: 241.331479\n",
      "\n",
      "[INFO] EPOCH: 210/1000\n",
      "Train loss: 373.975189\n",
      "Test loss: 239.471020\n",
      "\n",
      "[INFO] EPOCH: 211/1000\n",
      "Train loss: 358.625458\n",
      "Test loss: 241.848106\n",
      "\n",
      "[INFO] EPOCH: 212/1000\n",
      "Train loss: 376.179718\n",
      "Test loss: 240.176881\n",
      "\n",
      "[INFO] EPOCH: 213/1000\n",
      "Train loss: 382.023560\n",
      "Test loss: 238.307669\n",
      "\n",
      "[INFO] EPOCH: 214/1000\n",
      "Train loss: 368.933838\n",
      "Test loss: 237.636500\n",
      "\n",
      "[INFO] EPOCH: 215/1000\n",
      "Train loss: 372.998260\n",
      "Test loss: 234.735785\n",
      "\n",
      "[INFO] EPOCH: 216/1000\n",
      "Train loss: 361.357208\n",
      "Test loss: 234.562190\n",
      "\n",
      "[INFO] EPOCH: 217/1000\n",
      "Train loss: 383.279327\n",
      "Test loss: 236.488954\n",
      "\n",
      "[INFO] EPOCH: 218/1000\n",
      "Train loss: 390.593201\n",
      "Test loss: 235.367801\n",
      "\n",
      "[INFO] EPOCH: 219/1000\n",
      "Train loss: 386.238525\n",
      "Test loss: 230.940009\n",
      "\n",
      "[INFO] EPOCH: 220/1000\n",
      "Train loss: 393.794067\n",
      "Test loss: 229.236205\n",
      "\n",
      "[INFO] EPOCH: 221/1000\n",
      "Train loss: 373.162323\n",
      "Test loss: 231.047160\n",
      "\n",
      "[INFO] EPOCH: 222/1000\n",
      "Train loss: 384.764740\n",
      "Test loss: 229.957080\n",
      "\n",
      "[INFO] EPOCH: 223/1000\n",
      "Train loss: 389.320221\n",
      "Test loss: 232.095725\n",
      "\n",
      "[INFO] EPOCH: 224/1000\n",
      "Train loss: 364.622406\n",
      "Test loss: 231.049879\n",
      "\n",
      "[INFO] EPOCH: 225/1000\n",
      "Train loss: 360.056671\n",
      "Test loss: 231.437888\n",
      "\n",
      "[INFO] EPOCH: 226/1000\n",
      "Train loss: 334.308990\n",
      "Test loss: 230.012774\n",
      "\n",
      "[INFO] EPOCH: 227/1000\n",
      "Train loss: 366.301178\n",
      "Test loss: 230.154039\n",
      "\n",
      "[INFO] EPOCH: 228/1000\n",
      "Train loss: 394.014221\n",
      "Test loss: 230.765611\n",
      "\n",
      "[INFO] EPOCH: 229/1000\n",
      "Train loss: 358.030243\n",
      "Test loss: 232.761436\n",
      "\n",
      "[INFO] EPOCH: 230/1000\n",
      "Train loss: 377.565521\n",
      "Test loss: 231.301820\n",
      "\n",
      "[INFO] EPOCH: 231/1000\n",
      "Train loss: 341.032135\n",
      "Test loss: 232.681970\n",
      "\n",
      "[INFO] EPOCH: 232/1000\n",
      "Train loss: 347.964264\n",
      "Test loss: 231.165860\n",
      "\n",
      "[INFO] EPOCH: 233/1000\n",
      "Train loss: 401.264771\n",
      "Test loss: 231.443337\n",
      "\n",
      "[INFO] EPOCH: 234/1000\n",
      "Train loss: 353.621124\n",
      "Test loss: 229.044019\n",
      "\n",
      "[INFO] EPOCH: 235/1000\n",
      "Train loss: 373.056213\n",
      "Test loss: 228.711251\n",
      "\n",
      "[INFO] EPOCH: 236/1000\n",
      "Train loss: 360.528015\n",
      "Test loss: 229.402934\n",
      "\n",
      "[INFO] EPOCH: 237/1000\n",
      "Train loss: 369.764862\n",
      "Test loss: 228.948290\n",
      "\n",
      "[INFO] EPOCH: 238/1000\n",
      "Train loss: 427.053955\n",
      "Test loss: 226.712756\n",
      "\n",
      "[INFO] EPOCH: 239/1000\n",
      "Train loss: 369.528320\n",
      "Test loss: 227.647916\n",
      "\n",
      "[INFO] EPOCH: 240/1000\n",
      "Train loss: 381.147766\n",
      "Test loss: 227.011591\n",
      "\n",
      "[INFO] EPOCH: 241/1000\n",
      "Train loss: 335.572357\n",
      "Test loss: 223.950346\n",
      "\n",
      "[INFO] EPOCH: 242/1000\n",
      "Train loss: 356.125793\n",
      "Test loss: 224.268286\n",
      "\n",
      "[INFO] EPOCH: 243/1000\n",
      "Train loss: 384.394287\n",
      "Test loss: 221.169043\n",
      "\n",
      "[INFO] EPOCH: 244/1000\n",
      "Train loss: 390.203888\n",
      "Test loss: 222.102846\n",
      "\n",
      "[INFO] EPOCH: 245/1000\n",
      "Train loss: 369.013214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 220.354815\n",
      "\n",
      "[INFO] EPOCH: 246/1000\n",
      "Train loss: 355.331970\n",
      "Test loss: 219.971843\n",
      "\n",
      "[INFO] EPOCH: 247/1000\n",
      "Train loss: 347.721924\n",
      "Test loss: 218.810474\n",
      "\n",
      "[INFO] EPOCH: 248/1000\n",
      "Train loss: 360.367767\n",
      "Test loss: 218.674485\n",
      "\n",
      "[INFO] EPOCH: 249/1000\n",
      "Train loss: 366.737640\n",
      "Test loss: 218.949077\n",
      "\n",
      "[INFO] EPOCH: 250/1000\n",
      "Train loss: 364.861969\n",
      "Test loss: 218.248176\n",
      "\n",
      "[INFO] EPOCH: 251/1000\n",
      "Train loss: 335.738953\n",
      "Test loss: 219.091670\n",
      "\n",
      "[INFO] EPOCH: 252/1000\n",
      "Train loss: 358.591217\n",
      "Test loss: 217.998563\n",
      "\n",
      "[INFO] EPOCH: 253/1000\n",
      "Train loss: 367.871979\n",
      "Test loss: 219.006007\n",
      "\n",
      "[INFO] EPOCH: 254/1000\n",
      "Train loss: 366.463013\n",
      "Test loss: 219.011643\n",
      "\n",
      "[INFO] EPOCH: 255/1000\n",
      "Train loss: 313.323639\n",
      "Test loss: 221.445654\n",
      "\n",
      "[INFO] EPOCH: 256/1000\n",
      "Train loss: 387.680206\n",
      "Test loss: 220.078283\n",
      "\n",
      "[INFO] EPOCH: 257/1000\n",
      "Train loss: 380.633270\n",
      "Test loss: 222.637702\n",
      "\n",
      "[INFO] EPOCH: 258/1000\n",
      "Train loss: 358.745636\n",
      "Test loss: 223.422413\n",
      "\n",
      "[INFO] EPOCH: 259/1000\n",
      "Train loss: 355.039856\n",
      "Test loss: 222.481664\n",
      "\n",
      "[INFO] EPOCH: 260/1000\n",
      "Train loss: 357.723541\n",
      "Test loss: 222.195064\n",
      "\n",
      "[INFO] EPOCH: 261/1000\n",
      "Train loss: 364.769836\n",
      "Test loss: 221.389539\n",
      "\n",
      "[INFO] EPOCH: 262/1000\n",
      "Train loss: 385.016388\n",
      "Test loss: 220.014566\n",
      "\n",
      "[INFO] EPOCH: 263/1000\n",
      "Train loss: 377.560150\n",
      "Test loss: 219.961306\n",
      "\n",
      "[INFO] EPOCH: 264/1000\n",
      "Train loss: 366.356049\n",
      "Test loss: 221.447107\n",
      "\n",
      "[INFO] EPOCH: 265/1000\n",
      "Train loss: 323.230194\n",
      "Test loss: 220.599198\n",
      "\n",
      "[INFO] EPOCH: 266/1000\n",
      "Train loss: 330.184540\n",
      "Test loss: 218.384542\n",
      "\n",
      "[INFO] EPOCH: 267/1000\n",
      "Train loss: 358.356567\n",
      "Test loss: 216.949428\n",
      "\n",
      "[INFO] EPOCH: 268/1000\n",
      "Train loss: 331.586945\n",
      "Test loss: 218.305219\n",
      "\n",
      "[INFO] EPOCH: 269/1000\n",
      "Train loss: 346.625092\n",
      "Test loss: 217.862217\n",
      "\n",
      "[INFO] EPOCH: 270/1000\n",
      "Train loss: 345.938660\n",
      "Test loss: 216.109185\n",
      "\n",
      "[INFO] EPOCH: 271/1000\n",
      "Train loss: 338.170502\n",
      "Test loss: 216.115779\n",
      "\n",
      "[INFO] EPOCH: 272/1000\n",
      "Train loss: 373.745331\n",
      "Test loss: 215.695698\n",
      "\n",
      "[INFO] EPOCH: 273/1000\n",
      "Train loss: 356.016510\n",
      "Test loss: 216.517373\n",
      "\n",
      "[INFO] EPOCH: 274/1000\n",
      "Train loss: 348.618256\n",
      "Test loss: 216.953305\n",
      "\n",
      "[INFO] EPOCH: 275/1000\n",
      "Train loss: 329.732727\n",
      "Test loss: 218.719980\n",
      "\n",
      "[INFO] EPOCH: 276/1000\n",
      "Train loss: 366.036652\n",
      "Test loss: 217.086476\n",
      "\n",
      "[INFO] EPOCH: 277/1000\n",
      "Train loss: 342.953705\n",
      "Test loss: 215.837007\n",
      "\n",
      "[INFO] EPOCH: 278/1000\n",
      "Train loss: 338.206879\n",
      "Test loss: 214.681689\n",
      "\n",
      "[INFO] EPOCH: 279/1000\n",
      "Train loss: 350.844299\n",
      "Test loss: 215.619804\n",
      "\n",
      "[INFO] EPOCH: 280/1000\n",
      "Train loss: 344.437805\n",
      "Test loss: 215.581275\n",
      "\n",
      "[INFO] EPOCH: 281/1000\n",
      "Train loss: 321.887115\n",
      "Test loss: 214.008472\n",
      "\n",
      "[INFO] EPOCH: 282/1000\n",
      "Train loss: 343.001587\n",
      "Test loss: 213.211446\n",
      "\n",
      "[INFO] EPOCH: 283/1000\n",
      "Train loss: 357.366394\n",
      "Test loss: 212.864494\n",
      "\n",
      "[INFO] EPOCH: 284/1000\n",
      "Train loss: 340.376678\n",
      "Test loss: 213.417610\n",
      "\n",
      "[INFO] EPOCH: 285/1000\n",
      "Train loss: 376.885834\n",
      "Test loss: 215.173934\n",
      "\n",
      "[INFO] EPOCH: 286/1000\n",
      "Train loss: 358.263031\n",
      "Test loss: 214.513061\n",
      "\n",
      "[INFO] EPOCH: 287/1000\n",
      "Train loss: 338.163605\n",
      "Test loss: 214.761011\n",
      "\n",
      "[INFO] EPOCH: 288/1000\n",
      "Train loss: 343.907318\n",
      "Test loss: 215.645120\n",
      "\n",
      "[INFO] EPOCH: 289/1000\n",
      "Train loss: 341.245758\n",
      "Test loss: 213.966497\n",
      "\n",
      "[INFO] EPOCH: 290/1000\n",
      "Train loss: 388.469696\n",
      "Test loss: 213.674619\n",
      "\n",
      "[INFO] EPOCH: 291/1000\n",
      "Train loss: 352.075989\n",
      "Test loss: 210.939212\n",
      "\n",
      "[INFO] EPOCH: 292/1000\n",
      "Train loss: 329.306976\n",
      "Test loss: 210.930743\n",
      "\n",
      "[INFO] EPOCH: 293/1000\n",
      "Train loss: 347.133698\n",
      "Test loss: 211.597847\n",
      "\n",
      "[INFO] EPOCH: 294/1000\n",
      "Train loss: 346.819519\n",
      "Test loss: 212.402536\n",
      "\n",
      "[INFO] EPOCH: 295/1000\n",
      "Train loss: 338.912811\n",
      "Test loss: 212.356110\n",
      "\n",
      "[INFO] EPOCH: 296/1000\n",
      "Train loss: 319.606689\n",
      "Test loss: 212.083358\n",
      "\n",
      "[INFO] EPOCH: 297/1000\n",
      "Train loss: 351.279968\n",
      "Test loss: 213.729755\n",
      "\n",
      "[INFO] EPOCH: 298/1000\n",
      "Train loss: 332.360229\n",
      "Test loss: 213.159257\n",
      "\n",
      "[INFO] EPOCH: 299/1000\n",
      "Train loss: 355.215363\n",
      "Test loss: 211.558270\n",
      "\n",
      "[INFO] EPOCH: 300/1000\n",
      "Train loss: 385.410370\n",
      "Test loss: 210.922570\n",
      "\n",
      "[INFO] EPOCH: 301/1000\n",
      "Train loss: 330.433899\n",
      "Test loss: 211.380919\n",
      "\n",
      "[INFO] EPOCH: 302/1000\n",
      "Train loss: 325.204163\n",
      "Test loss: 210.122343\n",
      "\n",
      "[INFO] EPOCH: 303/1000\n",
      "Train loss: 320.089844\n",
      "Test loss: 210.067514\n",
      "\n",
      "[INFO] EPOCH: 304/1000\n",
      "Train loss: 345.199524\n",
      "Test loss: 210.090532\n",
      "\n",
      "[INFO] EPOCH: 305/1000\n",
      "Train loss: 339.180267\n",
      "Test loss: 210.614509\n",
      "\n",
      "[INFO] EPOCH: 306/1000\n",
      "Train loss: 322.970795\n",
      "Test loss: 210.646211\n",
      "\n",
      "[INFO] EPOCH: 307/1000\n",
      "Train loss: 337.878418\n",
      "Test loss: 209.532736\n",
      "\n",
      "[INFO] EPOCH: 308/1000\n",
      "Train loss: 365.784943\n",
      "Test loss: 209.081238\n",
      "\n",
      "[INFO] EPOCH: 309/1000\n",
      "Train loss: 350.623474\n",
      "Test loss: 208.359469\n",
      "\n",
      "[INFO] EPOCH: 310/1000\n",
      "Train loss: 345.713684\n",
      "Test loss: 208.240468\n",
      "\n",
      "[INFO] EPOCH: 311/1000\n",
      "Train loss: 331.469879\n",
      "Test loss: 207.911777\n",
      "\n",
      "[INFO] EPOCH: 312/1000\n",
      "Train loss: 327.298920\n",
      "Test loss: 207.535154\n",
      "\n",
      "[INFO] EPOCH: 313/1000\n",
      "Train loss: 335.050964\n",
      "Test loss: 208.539333\n",
      "\n",
      "[INFO] EPOCH: 314/1000\n",
      "Train loss: 329.070831\n",
      "Test loss: 207.954687\n",
      "\n",
      "[INFO] EPOCH: 315/1000\n",
      "Train loss: 342.237030\n",
      "Test loss: 208.971188\n",
      "\n",
      "[INFO] EPOCH: 316/1000\n",
      "Train loss: 340.162598\n",
      "Test loss: 208.521284\n",
      "\n",
      "[INFO] EPOCH: 317/1000\n",
      "Train loss: 334.831085\n",
      "Test loss: 207.320642\n",
      "\n",
      "[INFO] EPOCH: 318/1000\n",
      "Train loss: 337.321960\n",
      "Test loss: 207.515175\n",
      "\n",
      "[INFO] EPOCH: 319/1000\n",
      "Train loss: 347.573059\n",
      "Test loss: 206.499861\n",
      "\n",
      "[INFO] EPOCH: 320/1000\n",
      "Train loss: 334.675201\n",
      "Test loss: 206.566143\n",
      "\n",
      "[INFO] EPOCH: 321/1000\n",
      "Train loss: 345.177307\n",
      "Test loss: 206.939585\n",
      "\n",
      "[INFO] EPOCH: 322/1000\n",
      "Train loss: 329.646027\n",
      "Test loss: 208.369435\n",
      "\n",
      "[INFO] EPOCH: 323/1000\n",
      "Train loss: 364.149536\n",
      "Test loss: 208.227068\n",
      "\n",
      "[INFO] EPOCH: 324/1000\n",
      "Train loss: 338.179932\n",
      "Test loss: 208.055108\n",
      "\n",
      "[INFO] EPOCH: 325/1000\n",
      "Train loss: 299.497162\n",
      "Test loss: 207.338236\n",
      "\n",
      "[INFO] EPOCH: 326/1000\n",
      "Train loss: 312.094025\n",
      "Test loss: 207.202438\n",
      "\n",
      "[INFO] EPOCH: 327/1000\n",
      "Train loss: 320.859161\n",
      "Test loss: 207.940451\n",
      "\n",
      "[INFO] EPOCH: 328/1000\n",
      "Train loss: 344.034180\n",
      "Test loss: 207.815512\n",
      "\n",
      "[INFO] EPOCH: 329/1000\n",
      "Train loss: 353.570221\n",
      "Test loss: 207.329207\n",
      "\n",
      "[INFO] EPOCH: 330/1000\n",
      "Train loss: 369.745148\n",
      "Test loss: 207.892561\n",
      "\n",
      "[INFO] EPOCH: 331/1000\n",
      "Train loss: 317.309265\n",
      "Test loss: 207.241873\n",
      "\n",
      "[INFO] EPOCH: 332/1000\n",
      "Train loss: 328.555969\n",
      "Test loss: 207.683441\n",
      "\n",
      "[INFO] EPOCH: 333/1000\n",
      "Train loss: 335.147980\n",
      "Test loss: 208.759168\n",
      "\n",
      "[INFO] EPOCH: 334/1000\n",
      "Train loss: 354.455414\n",
      "Test loss: 207.791460\n",
      "\n",
      "[INFO] EPOCH: 335/1000\n",
      "Train loss: 320.563568\n",
      "Test loss: 206.690669\n",
      "\n",
      "[INFO] EPOCH: 336/1000\n",
      "Train loss: 325.916412\n",
      "Test loss: 206.755857\n",
      "\n",
      "[INFO] EPOCH: 337/1000\n",
      "Train loss: 335.839264\n",
      "Test loss: 206.411859\n",
      "\n",
      "[INFO] EPOCH: 338/1000\n",
      "Train loss: 354.050781\n",
      "Test loss: 206.253475\n",
      "\n",
      "[INFO] EPOCH: 339/1000\n",
      "Train loss: 346.085693\n",
      "Test loss: 205.498395\n",
      "\n",
      "[INFO] EPOCH: 340/1000\n",
      "Train loss: 312.987976\n",
      "Test loss: 205.897101\n",
      "\n",
      "[INFO] EPOCH: 341/1000\n",
      "Train loss: 326.249481\n",
      "Test loss: 205.017645\n",
      "\n",
      "[INFO] EPOCH: 342/1000\n",
      "Train loss: 322.299561\n",
      "Test loss: 204.460571\n",
      "\n",
      "[INFO] EPOCH: 343/1000\n",
      "Train loss: 353.681732\n",
      "Test loss: 204.586406\n",
      "\n",
      "[INFO] EPOCH: 344/1000\n",
      "Train loss: 329.191925\n",
      "Test loss: 204.783111\n",
      "\n",
      "[INFO] EPOCH: 345/1000\n",
      "Train loss: 321.364807\n",
      "Test loss: 204.840300\n",
      "\n",
      "[INFO] EPOCH: 346/1000\n",
      "Train loss: 315.232849\n",
      "Test loss: 204.866728\n",
      "\n",
      "[INFO] EPOCH: 347/1000\n",
      "Train loss: 308.683685\n",
      "Test loss: 205.105957\n",
      "\n",
      "[INFO] EPOCH: 348/1000\n",
      "Train loss: 327.170319\n",
      "Test loss: 205.407731\n",
      "\n",
      "[INFO] EPOCH: 349/1000\n",
      "Train loss: 352.956879\n",
      "Test loss: 205.794744\n",
      "\n",
      "[INFO] EPOCH: 350/1000\n",
      "Train loss: 326.187531\n",
      "Test loss: 205.910578\n",
      "\n",
      "[INFO] EPOCH: 351/1000\n",
      "Train loss: 354.175873\n",
      "Test loss: 204.899118\n",
      "\n",
      "[INFO] EPOCH: 352/1000\n",
      "Train loss: 322.105103\n",
      "Test loss: 204.547367\n",
      "\n",
      "[INFO] EPOCH: 353/1000\n",
      "Train loss: 354.205750\n",
      "Test loss: 204.317160\n",
      "\n",
      "[INFO] EPOCH: 354/1000\n",
      "Train loss: 326.988190\n",
      "Test loss: 205.257494\n",
      "\n",
      "[INFO] EPOCH: 355/1000\n",
      "Train loss: 310.702972\n",
      "Test loss: 205.511590\n",
      "\n",
      "[INFO] EPOCH: 356/1000\n",
      "Train loss: 300.167450\n",
      "Test loss: 205.583785\n",
      "\n",
      "[INFO] EPOCH: 357/1000\n",
      "Train loss: 353.637665\n",
      "Test loss: 204.300269\n",
      "\n",
      "[INFO] EPOCH: 358/1000\n",
      "Train loss: 308.279724\n",
      "Test loss: 204.042562\n",
      "\n",
      "[INFO] EPOCH: 359/1000\n",
      "Train loss: 312.696045\n",
      "Test loss: 204.269591\n",
      "\n",
      "[INFO] EPOCH: 360/1000\n",
      "Train loss: 315.550201\n",
      "Test loss: 204.050707\n",
      "\n",
      "[INFO] EPOCH: 361/1000\n",
      "Train loss: 316.702759\n",
      "Test loss: 204.558853\n",
      "\n",
      "[INFO] EPOCH: 362/1000\n",
      "Train loss: 320.569122\n",
      "Test loss: 203.986107\n",
      "\n",
      "[INFO] EPOCH: 363/1000\n",
      "Train loss: 318.393707\n",
      "Test loss: 203.662758\n",
      "\n",
      "[INFO] EPOCH: 364/1000\n",
      "Train loss: 332.399445\n",
      "Test loss: 203.100663\n",
      "\n",
      "[INFO] EPOCH: 365/1000\n",
      "Train loss: 362.692719\n",
      "Test loss: 202.660438\n",
      "\n",
      "[INFO] EPOCH: 366/1000\n",
      "Train loss: 327.826752\n",
      "Test loss: 201.989467\n",
      "\n",
      "[INFO] EPOCH: 367/1000\n",
      "Train loss: 329.832458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 202.039635\n",
      "\n",
      "[INFO] EPOCH: 368/1000\n",
      "Train loss: 323.773712\n",
      "Test loss: 202.064359\n",
      "\n",
      "[INFO] EPOCH: 369/1000\n",
      "Train loss: 361.721222\n",
      "Test loss: 202.271211\n",
      "\n",
      "[INFO] EPOCH: 370/1000\n",
      "Train loss: 319.548157\n",
      "Test loss: 202.361018\n",
      "\n",
      "[INFO] EPOCH: 371/1000\n",
      "Train loss: 354.052155\n",
      "Test loss: 202.123400\n",
      "\n",
      "[INFO] EPOCH: 372/1000\n",
      "Train loss: 313.843933\n",
      "Test loss: 202.221757\n",
      "\n",
      "[INFO] EPOCH: 373/1000\n",
      "Train loss: 323.150635\n",
      "Test loss: 202.174442\n",
      "\n",
      "[INFO] EPOCH: 374/1000\n",
      "Train loss: 320.456726\n",
      "Test loss: 201.958064\n",
      "\n",
      "[INFO] EPOCH: 375/1000\n",
      "Train loss: 329.505188\n",
      "Test loss: 202.082085\n",
      "\n",
      "[INFO] EPOCH: 376/1000\n",
      "Train loss: 337.825012\n",
      "Test loss: 202.361409\n",
      "\n",
      "[INFO] EPOCH: 377/1000\n",
      "Train loss: 339.201569\n",
      "Test loss: 202.678265\n",
      "\n",
      "[INFO] EPOCH: 378/1000\n",
      "Train loss: 340.102203\n",
      "Test loss: 203.296158\n",
      "\n",
      "[INFO] EPOCH: 379/1000\n",
      "Train loss: 382.040070\n",
      "Test loss: 203.064353\n",
      "\n",
      "[INFO] EPOCH: 380/1000\n",
      "Train loss: 291.692078\n",
      "Test loss: 203.475296\n",
      "\n",
      "[INFO] EPOCH: 381/1000\n",
      "Train loss: 306.453430\n",
      "Test loss: 203.087478\n",
      "\n",
      "[INFO] EPOCH: 382/1000\n",
      "Train loss: 338.152710\n",
      "Test loss: 202.720340\n",
      "\n",
      "[INFO] EPOCH: 383/1000\n",
      "Train loss: 316.577972\n",
      "Test loss: 202.860024\n",
      "\n",
      "[INFO] EPOCH: 384/1000\n",
      "Train loss: 313.381317\n",
      "Test loss: 202.442947\n",
      "\n",
      "[INFO] EPOCH: 385/1000\n",
      "Train loss: 369.072845\n",
      "Test loss: 202.224997\n",
      "\n",
      "[INFO] EPOCH: 386/1000\n",
      "Train loss: 302.352600\n",
      "Test loss: 202.527263\n",
      "\n",
      "[INFO] EPOCH: 387/1000\n",
      "Train loss: 334.471985\n",
      "Test loss: 202.550552\n",
      "\n",
      "[INFO] EPOCH: 388/1000\n",
      "Train loss: 312.394684\n",
      "Test loss: 201.900541\n",
      "\n",
      "[INFO] EPOCH: 389/1000\n",
      "Train loss: 326.336334\n",
      "Test loss: 202.028499\n",
      "\n",
      "[INFO] EPOCH: 390/1000\n",
      "Train loss: 334.594360\n",
      "Test loss: 201.493902\n",
      "\n",
      "[INFO] EPOCH: 391/1000\n",
      "Train loss: 332.130341\n",
      "Test loss: 201.287927\n",
      "\n",
      "[INFO] EPOCH: 392/1000\n",
      "Train loss: 313.124023\n",
      "Test loss: 201.294491\n",
      "\n",
      "[INFO] EPOCH: 393/1000\n",
      "Train loss: 324.886993\n",
      "Test loss: 201.228524\n",
      "\n",
      "[INFO] EPOCH: 394/1000\n",
      "Train loss: 310.166931\n",
      "Test loss: 201.201826\n",
      "\n",
      "[INFO] EPOCH: 395/1000\n",
      "Train loss: 304.685303\n",
      "Test loss: 201.177778\n",
      "\n",
      "[INFO] EPOCH: 396/1000\n",
      "Train loss: 322.130707\n",
      "Test loss: 201.028551\n",
      "\n",
      "[INFO] EPOCH: 397/1000\n",
      "Train loss: 349.047821\n",
      "Test loss: 200.834049\n",
      "\n",
      "[INFO] EPOCH: 398/1000\n",
      "Train loss: 325.754608\n",
      "Test loss: 200.979435\n",
      "\n",
      "[INFO] EPOCH: 399/1000\n",
      "Train loss: 331.101105\n",
      "Test loss: 201.050335\n",
      "\n",
      "[INFO] EPOCH: 400/1000\n",
      "Train loss: 326.574036\n",
      "Test loss: 201.163656\n",
      "\n",
      "[INFO] EPOCH: 401/1000\n",
      "Train loss: 307.129700\n",
      "Test loss: 200.871330\n",
      "\n",
      "[INFO] EPOCH: 402/1000\n",
      "Train loss: 306.102081\n",
      "Test loss: 200.730916\n",
      "\n",
      "[INFO] EPOCH: 403/1000\n",
      "Train loss: 311.675659\n",
      "Test loss: 200.711149\n",
      "\n",
      "[INFO] EPOCH: 404/1000\n",
      "Train loss: 366.178284\n",
      "Test loss: 200.676909\n",
      "\n",
      "[INFO] EPOCH: 405/1000\n",
      "Train loss: 303.906555\n",
      "Test loss: 200.732585\n",
      "\n",
      "[INFO] EPOCH: 406/1000\n",
      "Train loss: 338.971008\n",
      "Test loss: 200.655396\n",
      "\n",
      "[INFO] EPOCH: 407/1000\n",
      "Train loss: 296.140625\n",
      "Test loss: 200.863169\n",
      "\n",
      "[INFO] EPOCH: 408/1000\n",
      "Train loss: 300.471588\n",
      "Test loss: 201.348749\n",
      "\n",
      "[INFO] EPOCH: 409/1000\n",
      "Train loss: 319.743347\n",
      "Test loss: 200.919473\n",
      "\n",
      "[INFO] EPOCH: 410/1000\n",
      "Train loss: 307.617004\n",
      "Test loss: 200.834020\n",
      "\n",
      "[INFO] EPOCH: 411/1000\n",
      "Train loss: 290.493958\n",
      "Test loss: 200.660877\n",
      "\n",
      "[INFO] EPOCH: 412/1000\n",
      "Train loss: 324.192291\n",
      "Test loss: 200.570378\n",
      "\n",
      "[INFO] EPOCH: 413/1000\n",
      "Train loss: 309.121460\n",
      "Test loss: 200.536083\n",
      "\n",
      "[INFO] EPOCH: 414/1000\n",
      "Train loss: 324.507782\n",
      "Test loss: 200.679939\n",
      "\n",
      "[INFO] EPOCH: 415/1000\n",
      "Train loss: 314.495300\n",
      "Test loss: 200.734682\n",
      "\n",
      "[INFO] EPOCH: 416/1000\n",
      "Train loss: 295.979187\n",
      "Test loss: 200.655164\n",
      "\n",
      "[INFO] EPOCH: 417/1000\n",
      "Train loss: 295.164764\n",
      "Test loss: 200.713164\n",
      "\n",
      "[INFO] EPOCH: 418/1000\n",
      "Train loss: 302.262024\n",
      "Test loss: 200.667737\n",
      "\n",
      "[INFO] EPOCH: 419/1000\n",
      "Train loss: 319.145111\n",
      "Test loss: 200.568274\n",
      "\n",
      "[INFO] EPOCH: 420/1000\n",
      "Train loss: 323.217041\n",
      "Test loss: 200.505611\n",
      "\n",
      "[INFO] EPOCH: 421/1000\n",
      "Train loss: 299.201263\n",
      "Test loss: 200.426745\n",
      "\n",
      "[INFO] EPOCH: 422/1000\n",
      "Train loss: 330.974487\n",
      "Test loss: 200.454252\n",
      "\n",
      "[INFO] EPOCH: 423/1000\n",
      "Train loss: 293.771790\n",
      "Test loss: 200.484614\n",
      "\n",
      "[INFO] EPOCH: 424/1000\n",
      "Train loss: 349.761719\n",
      "Test loss: 200.361330\n",
      "\n",
      "[INFO] EPOCH: 425/1000\n",
      "Train loss: 314.792358\n",
      "Test loss: 200.353819\n",
      "\n",
      "[INFO] EPOCH: 426/1000\n",
      "Train loss: 316.717194\n",
      "Test loss: 200.520725\n",
      "\n",
      "[INFO] EPOCH: 427/1000\n",
      "Train loss: 291.221130\n",
      "Test loss: 200.324709\n",
      "\n",
      "[INFO] EPOCH: 428/1000\n",
      "Train loss: 301.058014\n",
      "Test loss: 200.268852\n",
      "\n",
      "[INFO] EPOCH: 429/1000\n",
      "Train loss: 321.477722\n",
      "Test loss: 200.255864\n",
      "\n",
      "[INFO] EPOCH: 430/1000\n",
      "Train loss: 333.528015\n",
      "Test loss: 200.239846\n",
      "\n",
      "[INFO] EPOCH: 431/1000\n",
      "Train loss: 325.685852\n",
      "Test loss: 200.399755\n",
      "\n",
      "[INFO] EPOCH: 432/1000\n",
      "Train loss: 353.597076\n",
      "Test loss: 200.215310\n",
      "\n",
      "[INFO] EPOCH: 433/1000\n",
      "Train loss: 309.628479\n",
      "Test loss: 200.179444\n",
      "\n",
      "[INFO] EPOCH: 434/1000\n",
      "Train loss: 307.050781\n",
      "Test loss: 200.177526\n",
      "\n",
      "[INFO] EPOCH: 435/1000\n",
      "Train loss: 312.092987\n",
      "Test loss: 200.182475\n",
      "\n",
      "[INFO] EPOCH: 436/1000\n",
      "Train loss: 321.862030\n",
      "Test loss: 200.184784\n",
      "\n",
      "[INFO] EPOCH: 437/1000\n",
      "Train loss: 325.793152\n",
      "Test loss: 200.157820\n",
      "\n",
      "[INFO] EPOCH: 438/1000\n",
      "Train loss: 325.662201\n",
      "Test loss: 200.119499\n",
      "\n",
      "[INFO] EPOCH: 439/1000\n",
      "Train loss: 297.974091\n",
      "Test loss: 200.123401\n",
      "\n",
      "[INFO] EPOCH: 440/1000\n",
      "Train loss: 335.561920\n",
      "Test loss: 200.064976\n",
      "\n",
      "[INFO] EPOCH: 441/1000\n",
      "Train loss: 321.919403\n",
      "Test loss: 200.138313\n",
      "\n",
      "[INFO] EPOCH: 442/1000\n",
      "Train loss: 346.534241\n",
      "Test loss: 200.172203\n",
      "\n",
      "[INFO] EPOCH: 443/1000\n",
      "Train loss: 294.897552\n",
      "Test loss: 200.357076\n",
      "\n",
      "[INFO] EPOCH: 444/1000\n",
      "Train loss: 306.917725\n",
      "Test loss: 200.466665\n",
      "\n",
      "[INFO] EPOCH: 445/1000\n",
      "Train loss: 297.545990\n",
      "Test loss: 200.520823\n",
      "\n",
      "[INFO] EPOCH: 446/1000\n",
      "Train loss: 318.865906\n",
      "Test loss: 200.435316\n",
      "\n",
      "[INFO] EPOCH: 447/1000\n",
      "Train loss: 322.322693\n",
      "Test loss: 200.742366\n",
      "\n",
      "[INFO] EPOCH: 448/1000\n",
      "Train loss: 356.377289\n",
      "Test loss: 200.619120\n",
      "\n",
      "[INFO] EPOCH: 449/1000\n",
      "Train loss: 306.224701\n",
      "Test loss: 200.203721\n",
      "\n",
      "[INFO] EPOCH: 450/1000\n",
      "Train loss: 300.489624\n",
      "Test loss: 200.056116\n",
      "\n",
      "[INFO] EPOCH: 451/1000\n",
      "Train loss: 303.195099\n",
      "Test loss: 200.051890\n",
      "\n",
      "[INFO] EPOCH: 452/1000\n",
      "Train loss: 301.416321\n",
      "Test loss: 199.882224\n",
      "\n",
      "[INFO] EPOCH: 453/1000\n",
      "Train loss: 325.604889\n",
      "Test loss: 199.866677\n",
      "\n",
      "[INFO] EPOCH: 454/1000\n",
      "Train loss: 322.063873\n",
      "Test loss: 199.868824\n",
      "\n",
      "[INFO] EPOCH: 455/1000\n",
      "Train loss: 319.012451\n",
      "Test loss: 200.046454\n",
      "\n",
      "[INFO] EPOCH: 456/1000\n",
      "Train loss: 320.219360\n",
      "Test loss: 199.954655\n",
      "\n",
      "[INFO] EPOCH: 457/1000\n",
      "Train loss: 299.793274\n",
      "Test loss: 200.018912\n",
      "\n",
      "[INFO] EPOCH: 458/1000\n",
      "Train loss: 301.697449\n",
      "Test loss: 199.966359\n",
      "\n",
      "[INFO] EPOCH: 459/1000\n",
      "Train loss: 290.259094\n",
      "Test loss: 199.812381\n",
      "\n",
      "[INFO] EPOCH: 460/1000\n",
      "Train loss: 324.274384\n",
      "Test loss: 199.837022\n",
      "\n",
      "[INFO] EPOCH: 461/1000\n",
      "Train loss: 304.743469\n",
      "Test loss: 199.890099\n",
      "\n",
      "[INFO] EPOCH: 462/1000\n",
      "Train loss: 310.365265\n",
      "Test loss: 200.000260\n",
      "\n",
      "[INFO] EPOCH: 463/1000\n",
      "Train loss: 310.413971\n",
      "Test loss: 199.782418\n",
      "\n",
      "[INFO] EPOCH: 464/1000\n",
      "Train loss: 302.713470\n",
      "Test loss: 199.783214\n",
      "\n",
      "[INFO] EPOCH: 465/1000\n",
      "Train loss: 337.893890\n",
      "Test loss: 199.762371\n",
      "\n",
      "[INFO] EPOCH: 466/1000\n",
      "Train loss: 378.568878\n",
      "Test loss: 199.759845\n",
      "\n",
      "[INFO] EPOCH: 467/1000\n",
      "Train loss: 294.966431\n",
      "Test loss: 199.744270\n",
      "\n",
      "[INFO] EPOCH: 468/1000\n",
      "Train loss: 316.236023\n",
      "Test loss: 199.783858\n",
      "\n",
      "[INFO] EPOCH: 469/1000\n",
      "Train loss: 316.698212\n",
      "Test loss: 199.873106\n",
      "\n",
      "[INFO] EPOCH: 470/1000\n",
      "Train loss: 315.228333\n",
      "Test loss: 200.071929\n",
      "\n",
      "[INFO] EPOCH: 471/1000\n",
      "Train loss: 308.892120\n",
      "Test loss: 199.910214\n",
      "\n",
      "[INFO] EPOCH: 472/1000\n",
      "Train loss: 311.520630\n",
      "Test loss: 200.335169\n",
      "\n",
      "[INFO] EPOCH: 473/1000\n",
      "Train loss: 293.630585\n",
      "Test loss: 200.142883\n",
      "\n",
      "[INFO] EPOCH: 474/1000\n",
      "Train loss: 289.029114\n",
      "Test loss: 199.765579\n",
      "\n",
      "[INFO] EPOCH: 475/1000\n",
      "Train loss: 303.169678\n",
      "Test loss: 199.703951\n",
      "\n",
      "[INFO] EPOCH: 476/1000\n",
      "Train loss: 299.848938\n",
      "Test loss: 199.767665\n",
      "\n",
      "[INFO] EPOCH: 477/1000\n",
      "Train loss: 330.443451\n",
      "Test loss: 199.782174\n",
      "\n",
      "[INFO] EPOCH: 478/1000\n",
      "Train loss: 338.411804\n",
      "Test loss: 199.733787\n",
      "\n",
      "[INFO] EPOCH: 479/1000\n",
      "Train loss: 321.508118\n",
      "Test loss: 199.632346\n",
      "\n",
      "[INFO] EPOCH: 480/1000\n",
      "Train loss: 322.946320\n",
      "Test loss: 199.658788\n",
      "\n",
      "[INFO] EPOCH: 481/1000\n",
      "Train loss: 301.077057\n",
      "Test loss: 199.769888\n",
      "\n",
      "[INFO] EPOCH: 482/1000\n",
      "Train loss: 307.779816\n",
      "Test loss: 199.900994\n",
      "\n",
      "[INFO] EPOCH: 483/1000\n",
      "Train loss: 314.680267\n",
      "Test loss: 200.123813\n",
      "\n",
      "[INFO] EPOCH: 484/1000\n",
      "Train loss: 272.736450\n",
      "Test loss: 200.138226\n",
      "\n",
      "[INFO] EPOCH: 485/1000\n",
      "Train loss: 314.877838\n",
      "Test loss: 200.158630\n",
      "\n",
      "[INFO] EPOCH: 486/1000\n",
      "Train loss: 292.770966\n",
      "Test loss: 199.981954\n",
      "\n",
      "[INFO] EPOCH: 487/1000\n",
      "Train loss: 295.316925\n",
      "Test loss: 199.849662\n",
      "\n",
      "[INFO] EPOCH: 488/1000\n",
      "Train loss: 291.922638\n",
      "Test loss: 199.625212\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] EPOCH: 489/1000\n",
      "Train loss: 309.164948\n",
      "Test loss: 199.549528\n",
      "\n",
      "[INFO] EPOCH: 490/1000\n",
      "Train loss: 312.819305\n",
      "Test loss: 199.586901\n",
      "\n",
      "[INFO] EPOCH: 491/1000\n",
      "Train loss: 316.622528\n",
      "Test loss: 199.681186\n",
      "\n",
      "[INFO] EPOCH: 492/1000\n",
      "Train loss: 322.421661\n",
      "Test loss: 199.758574\n",
      "\n",
      "[INFO] EPOCH: 493/1000\n",
      "Train loss: 310.615204\n",
      "Test loss: 199.792803\n",
      "\n",
      "[INFO] EPOCH: 494/1000\n",
      "Train loss: 320.634583\n",
      "Test loss: 199.666175\n",
      "\n",
      "[INFO] EPOCH: 495/1000\n",
      "Train loss: 307.230835\n",
      "Test loss: 199.730616\n",
      "\n",
      "[INFO] EPOCH: 496/1000\n",
      "Train loss: 296.568878\n",
      "Test loss: 200.041684\n",
      "\n",
      "[INFO] EPOCH: 497/1000\n",
      "Train loss: 308.231354\n",
      "Test loss: 199.721932\n",
      "\n",
      "[INFO] EPOCH: 498/1000\n",
      "Train loss: 323.415131\n",
      "Test loss: 199.771036\n",
      "\n",
      "[INFO] EPOCH: 499/1000\n",
      "Train loss: 304.405182\n",
      "Test loss: 199.658870\n",
      "\n",
      "[INFO] EPOCH: 500/1000\n",
      "Train loss: 301.351685\n",
      "Test loss: 199.602326\n",
      "\n",
      "[INFO] EPOCH: 501/1000\n",
      "Train loss: 297.517578\n",
      "Test loss: 199.679609\n",
      "\n",
      "[INFO] EPOCH: 502/1000\n",
      "Train loss: 339.016357\n",
      "Test loss: 199.654545\n",
      "\n",
      "[INFO] EPOCH: 503/1000\n",
      "Train loss: 303.160950\n",
      "Test loss: 199.824590\n",
      "\n",
      "[INFO] EPOCH: 504/1000\n",
      "Train loss: 291.118958\n",
      "Test loss: 200.467383\n",
      "\n",
      "[INFO] EPOCH: 505/1000\n",
      "Train loss: 287.404572\n",
      "Test loss: 200.710397\n",
      "\n",
      "[INFO] EPOCH: 506/1000\n",
      "Train loss: 300.946991\n",
      "Test loss: 200.834896\n",
      "\n",
      "[INFO] EPOCH: 507/1000\n",
      "Train loss: 309.003815\n",
      "Test loss: 200.315284\n",
      "\n",
      "[INFO] EPOCH: 508/1000\n",
      "Train loss: 305.778198\n",
      "Test loss: 200.131524\n",
      "\n",
      "[INFO] EPOCH: 509/1000\n",
      "Train loss: 339.646454\n",
      "Test loss: 200.706986\n",
      "\n",
      "[INFO] EPOCH: 510/1000\n",
      "Train loss: 320.459412\n",
      "Test loss: 199.987041\n",
      "\n",
      "[INFO] EPOCH: 511/1000\n",
      "Train loss: 336.392609\n",
      "Test loss: 200.016405\n",
      "\n",
      "[INFO] EPOCH: 512/1000\n",
      "Train loss: 305.423035\n",
      "Test loss: 200.560447\n",
      "\n",
      "[INFO] EPOCH: 513/1000\n",
      "Train loss: 324.063141\n",
      "Test loss: 200.723530\n",
      "\n",
      "[INFO] EPOCH: 514/1000\n",
      "Train loss: 279.500244\n",
      "Test loss: 200.905875\n",
      "\n",
      "[INFO] EPOCH: 515/1000\n",
      "Train loss: 315.635651\n",
      "Test loss: 200.482932\n",
      "\n",
      "[INFO] EPOCH: 516/1000\n",
      "Train loss: 288.435638\n",
      "Test loss: 200.152782\n",
      "\n",
      "[INFO] EPOCH: 517/1000\n",
      "Train loss: 289.534180\n",
      "Test loss: 200.446813\n",
      "\n",
      "[INFO] EPOCH: 518/1000\n",
      "Train loss: 318.102631\n",
      "Test loss: 200.733658\n",
      "\n",
      "[INFO] EPOCH: 519/1000\n",
      "Train loss: 266.838348\n",
      "Test loss: 200.310316\n",
      "\n",
      "[INFO] EPOCH: 520/1000\n",
      "Train loss: 297.064392\n",
      "Test loss: 200.169395\n",
      "\n",
      "[INFO] EPOCH: 521/1000\n",
      "Train loss: 339.916199\n",
      "Test loss: 200.065521\n",
      "\n",
      "[INFO] EPOCH: 522/1000\n",
      "Train loss: 279.156799\n",
      "Test loss: 199.617659\n",
      "\n",
      "[INFO] EPOCH: 523/1000\n",
      "Train loss: 324.750671\n",
      "Test loss: 199.690382\n",
      "\n",
      "[INFO] EPOCH: 524/1000\n",
      "Train loss: 295.342865\n",
      "Test loss: 199.704944\n",
      "\n",
      "[INFO] EPOCH: 525/1000\n",
      "Train loss: 294.014343\n",
      "Test loss: 199.948137\n",
      "\n",
      "[INFO] EPOCH: 526/1000\n",
      "Train loss: 299.760986\n",
      "Test loss: 199.945281\n",
      "\n",
      "[INFO] EPOCH: 527/1000\n",
      "Train loss: 297.174683\n",
      "Test loss: 199.820172\n",
      "\n",
      "[INFO] EPOCH: 528/1000\n",
      "Train loss: 317.708038\n",
      "Test loss: 199.770744\n",
      "\n",
      "[INFO] EPOCH: 529/1000\n",
      "Train loss: 301.547150\n",
      "Test loss: 199.398662\n",
      "\n",
      "[INFO] EPOCH: 530/1000\n",
      "Train loss: 311.645325\n",
      "Test loss: 199.368276\n",
      "\n",
      "[INFO] EPOCH: 531/1000\n",
      "Train loss: 322.127869\n",
      "Test loss: 199.710530\n",
      "\n",
      "[INFO] EPOCH: 532/1000\n",
      "Train loss: 296.994690\n",
      "Test loss: 199.496347\n",
      "\n",
      "[INFO] EPOCH: 533/1000\n",
      "Train loss: 298.387604\n",
      "Test loss: 199.702617\n",
      "\n",
      "[INFO] EPOCH: 534/1000\n",
      "Train loss: 284.813965\n",
      "Test loss: 199.420427\n",
      "\n",
      "[INFO] EPOCH: 535/1000\n",
      "Train loss: 305.021881\n",
      "Test loss: 199.731645\n",
      "\n",
      "[INFO] EPOCH: 536/1000\n",
      "Train loss: 296.879120\n",
      "Test loss: 200.087326\n",
      "\n",
      "[INFO] EPOCH: 537/1000\n",
      "Train loss: 306.199554\n",
      "Test loss: 200.536202\n",
      "\n",
      "[INFO] EPOCH: 538/1000\n",
      "Train loss: 313.278625\n",
      "Test loss: 200.086701\n",
      "\n",
      "[INFO] EPOCH: 539/1000\n",
      "Train loss: 297.290192\n",
      "Test loss: 200.272780\n",
      "\n",
      "[INFO] EPOCH: 540/1000\n",
      "Train loss: 296.351868\n",
      "Test loss: 200.615914\n",
      "\n",
      "[INFO] EPOCH: 541/1000\n",
      "Train loss: 284.811798\n",
      "Test loss: 200.208502\n",
      "\n",
      "[INFO] EPOCH: 542/1000\n",
      "Train loss: 318.522217\n",
      "Test loss: 200.129893\n",
      "\n",
      "[INFO] EPOCH: 543/1000\n",
      "Train loss: 304.889679\n",
      "Test loss: 200.984068\n",
      "\n",
      "[INFO] EPOCH: 544/1000\n",
      "Train loss: 320.373322\n",
      "Test loss: 200.866689\n",
      "\n",
      "[INFO] EPOCH: 545/1000\n",
      "Train loss: 297.339569\n",
      "Test loss: 200.643748\n",
      "\n",
      "[INFO] EPOCH: 546/1000\n",
      "Train loss: 298.360046\n",
      "Test loss: 200.180960\n",
      "\n",
      "[INFO] EPOCH: 547/1000\n",
      "Train loss: 283.613251\n",
      "Test loss: 200.560049\n",
      "\n",
      "[INFO] EPOCH: 548/1000\n",
      "Train loss: 286.263641\n",
      "Test loss: 200.243099\n",
      "\n",
      "[INFO] EPOCH: 549/1000\n",
      "Train loss: 323.000031\n",
      "Test loss: 201.154641\n",
      "\n",
      "[INFO] EPOCH: 550/1000\n",
      "Train loss: 345.170807\n",
      "Test loss: 200.585830\n",
      "\n",
      "[INFO] EPOCH: 551/1000\n",
      "Train loss: 345.532684\n",
      "Test loss: 200.473212\n",
      "\n",
      "[INFO] EPOCH: 552/1000\n",
      "Train loss: 331.826843\n",
      "Test loss: 201.239486\n",
      "\n",
      "[INFO] EPOCH: 553/1000\n",
      "Train loss: 293.683807\n",
      "Test loss: 200.797532\n",
      "\n",
      "[INFO] EPOCH: 554/1000\n",
      "Train loss: 311.163971\n",
      "Test loss: 199.891843\n",
      "\n",
      "[INFO] EPOCH: 555/1000\n",
      "Train loss: 298.430450\n",
      "Test loss: 199.197914\n",
      "\n",
      "[INFO] EPOCH: 556/1000\n",
      "Train loss: 293.674774\n",
      "Test loss: 199.383114\n",
      "\n",
      "[INFO] EPOCH: 557/1000\n",
      "Train loss: 292.903290\n",
      "Test loss: 199.240021\n",
      "\n",
      "[INFO] EPOCH: 558/1000\n",
      "Train loss: 313.184479\n",
      "Test loss: 199.337932\n",
      "\n",
      "[INFO] EPOCH: 559/1000\n",
      "Train loss: 310.057892\n",
      "Test loss: 200.116198\n",
      "\n",
      "[INFO] EPOCH: 560/1000\n",
      "Train loss: 291.351318\n",
      "Test loss: 200.542811\n",
      "\n",
      "[INFO] EPOCH: 561/1000\n",
      "Train loss: 281.334045\n",
      "Test loss: 200.864353\n",
      "\n",
      "[INFO] EPOCH: 562/1000\n",
      "Train loss: 310.321259\n",
      "Test loss: 200.667190\n",
      "\n",
      "[INFO] EPOCH: 563/1000\n",
      "Train loss: 304.217865\n",
      "Test loss: 201.125083\n",
      "\n",
      "[INFO] EPOCH: 564/1000\n",
      "Train loss: 280.913605\n",
      "Test loss: 201.050616\n",
      "\n",
      "[INFO] EPOCH: 565/1000\n",
      "Train loss: 289.518463\n",
      "Test loss: 200.458353\n",
      "\n",
      "[INFO] EPOCH: 566/1000\n",
      "Train loss: 296.037506\n",
      "Test loss: 201.128599\n",
      "\n",
      "[INFO] EPOCH: 567/1000\n",
      "Train loss: 312.416107\n",
      "Test loss: 200.987850\n",
      "\n",
      "[INFO] EPOCH: 568/1000\n",
      "Train loss: 306.451324\n",
      "Test loss: 200.169230\n",
      "\n",
      "[INFO] EPOCH: 569/1000\n",
      "Train loss: 296.598236\n",
      "Test loss: 200.265370\n",
      "\n",
      "[INFO] EPOCH: 570/1000\n",
      "Train loss: 268.633301\n",
      "Test loss: 199.993635\n",
      "\n",
      "[INFO] EPOCH: 571/1000\n",
      "Train loss: 305.127136\n",
      "Test loss: 199.819598\n",
      "\n",
      "[INFO] EPOCH: 572/1000\n",
      "Train loss: 319.436798\n",
      "Test loss: 200.041929\n",
      "\n",
      "[INFO] EPOCH: 573/1000\n",
      "Train loss: 315.216034\n",
      "Test loss: 200.048762\n",
      "\n",
      "[INFO] EPOCH: 574/1000\n",
      "Train loss: 328.642273\n",
      "Test loss: 199.724681\n",
      "\n",
      "[INFO] EPOCH: 575/1000\n",
      "Train loss: 267.906708\n",
      "Test loss: 199.552336\n",
      "\n",
      "[INFO] EPOCH: 576/1000\n",
      "Train loss: 293.676239\n",
      "Test loss: 199.474169\n",
      "\n",
      "[INFO] EPOCH: 577/1000\n",
      "Train loss: 299.689972\n",
      "Test loss: 200.097970\n",
      "\n",
      "[INFO] EPOCH: 578/1000\n",
      "Train loss: 300.385986\n",
      "Test loss: 200.345384\n",
      "\n",
      "[INFO] EPOCH: 579/1000\n",
      "Train loss: 287.698944\n",
      "Test loss: 200.366038\n",
      "\n",
      "[INFO] EPOCH: 580/1000\n",
      "Train loss: 270.191711\n",
      "Test loss: 200.341592\n",
      "\n",
      "[INFO] EPOCH: 581/1000\n",
      "Train loss: 298.222595\n",
      "Test loss: 199.928502\n",
      "\n",
      "[INFO] EPOCH: 582/1000\n",
      "Train loss: 316.911133\n",
      "Test loss: 200.336112\n",
      "\n",
      "[INFO] EPOCH: 583/1000\n",
      "Train loss: 311.476440\n",
      "Test loss: 200.292674\n",
      "\n",
      "[INFO] EPOCH: 584/1000\n",
      "Train loss: 282.458099\n",
      "Test loss: 200.651869\n",
      "\n",
      "[INFO] EPOCH: 585/1000\n",
      "Train loss: 299.768799\n",
      "Test loss: 200.939634\n",
      "\n",
      "[INFO] EPOCH: 586/1000\n",
      "Train loss: 290.984253\n",
      "Test loss: 200.543551\n",
      "\n",
      "[INFO] EPOCH: 587/1000\n",
      "Train loss: 319.692505\n",
      "Test loss: 201.507905\n",
      "\n",
      "[INFO] EPOCH: 588/1000\n",
      "Train loss: 300.397736\n",
      "Test loss: 201.955385\n",
      "\n",
      "[INFO] EPOCH: 589/1000\n",
      "Train loss: 289.464294\n",
      "Test loss: 201.076305\n",
      "\n",
      "[INFO] EPOCH: 590/1000\n",
      "Train loss: 296.589661\n",
      "Test loss: 201.248356\n",
      "\n",
      "[INFO] EPOCH: 591/1000\n",
      "Train loss: 317.380157\n",
      "Test loss: 201.528784\n",
      "\n",
      "[INFO] EPOCH: 592/1000\n",
      "Train loss: 303.174561\n",
      "Test loss: 201.591064\n",
      "\n",
      "[INFO] EPOCH: 593/1000\n",
      "Train loss: 291.621490\n",
      "Test loss: 201.695837\n",
      "\n",
      "[INFO] EPOCH: 594/1000\n",
      "Train loss: 272.115204\n",
      "Test loss: 201.503038\n",
      "\n",
      "[INFO] EPOCH: 595/1000\n",
      "Train loss: 299.683441\n",
      "Test loss: 201.242626\n",
      "\n",
      "[INFO] EPOCH: 596/1000\n",
      "Train loss: 312.955811\n",
      "Test loss: 201.445295\n",
      "\n",
      "[INFO] EPOCH: 597/1000\n",
      "Train loss: 319.118683\n",
      "Test loss: 200.935302\n",
      "\n",
      "[INFO] EPOCH: 598/1000\n",
      "Train loss: 297.691132\n",
      "Test loss: 201.795357\n",
      "\n",
      "[INFO] EPOCH: 599/1000\n",
      "Train loss: 294.995514\n",
      "Test loss: 202.408203\n",
      "\n",
      "[INFO] EPOCH: 600/1000\n",
      "Train loss: 300.697357\n",
      "Test loss: 202.458738\n",
      "\n",
      "[INFO] EPOCH: 601/1000\n",
      "Train loss: 315.263367\n",
      "Test loss: 201.864391\n",
      "\n",
      "[INFO] EPOCH: 602/1000\n",
      "Train loss: 312.613464\n",
      "Test loss: 201.941823\n",
      "\n",
      "[INFO] EPOCH: 603/1000\n",
      "Train loss: 313.249969\n",
      "Test loss: 202.108090\n",
      "\n",
      "[INFO] EPOCH: 604/1000\n",
      "Train loss: 296.096283\n",
      "Test loss: 201.457937\n",
      "\n",
      "[INFO] EPOCH: 605/1000\n",
      "Train loss: 287.160553\n",
      "Test loss: 200.479428\n",
      "\n",
      "[INFO] EPOCH: 606/1000\n",
      "Train loss: 297.341461\n",
      "Test loss: 201.013686\n",
      "\n",
      "[INFO] EPOCH: 607/1000\n",
      "Train loss: 315.941620\n",
      "Test loss: 201.575398\n",
      "\n",
      "[INFO] EPOCH: 608/1000\n",
      "Train loss: 294.976257\n",
      "Test loss: 203.055121\n",
      "\n",
      "[INFO] EPOCH: 609/1000\n",
      "Train loss: 293.840515\n",
      "Test loss: 202.859498\n",
      "\n",
      "[INFO] EPOCH: 610/1000\n",
      "Train loss: 310.672333\n",
      "Test loss: 202.072944\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] EPOCH: 611/1000\n",
      "Train loss: 293.561920\n",
      "Test loss: 201.494269\n",
      "\n",
      "[INFO] EPOCH: 612/1000\n",
      "Train loss: 298.989380\n",
      "Test loss: 202.065144\n",
      "\n",
      "[INFO] EPOCH: 613/1000\n",
      "Train loss: 279.163788\n",
      "Test loss: 202.179294\n",
      "\n",
      "[INFO] EPOCH: 614/1000\n",
      "Train loss: 280.191589\n",
      "Test loss: 202.351974\n",
      "\n",
      "[INFO] EPOCH: 615/1000\n",
      "Train loss: 289.477386\n",
      "Test loss: 201.536040\n",
      "\n",
      "[INFO] EPOCH: 616/1000\n",
      "Train loss: 301.764496\n",
      "Test loss: 201.669372\n",
      "\n",
      "[INFO] EPOCH: 617/1000\n",
      "Train loss: 285.709229\n",
      "Test loss: 200.613788\n",
      "\n",
      "[INFO] EPOCH: 618/1000\n",
      "Train loss: 298.977325\n",
      "Test loss: 201.050660\n",
      "\n",
      "[INFO] EPOCH: 619/1000\n",
      "Train loss: 304.052673\n",
      "Test loss: 201.228637\n",
      "\n",
      "[INFO] EPOCH: 620/1000\n",
      "Train loss: 286.990631\n",
      "Test loss: 201.710309\n",
      "\n",
      "[INFO] EPOCH: 621/1000\n",
      "Train loss: 293.604340\n",
      "Test loss: 202.471039\n",
      "\n",
      "[INFO] EPOCH: 622/1000\n",
      "Train loss: 304.543915\n",
      "Test loss: 202.396754\n",
      "\n",
      "[INFO] EPOCH: 623/1000\n",
      "Train loss: 279.232910\n",
      "Test loss: 201.534850\n",
      "\n",
      "[INFO] EPOCH: 624/1000\n",
      "Train loss: 297.023438\n",
      "Test loss: 202.052910\n",
      "\n",
      "[INFO] EPOCH: 625/1000\n",
      "Train loss: 302.498688\n",
      "Test loss: 203.243416\n",
      "\n",
      "[INFO] EPOCH: 626/1000\n",
      "Train loss: 316.447845\n",
      "Test loss: 202.353059\n",
      "\n",
      "[INFO] EPOCH: 627/1000\n",
      "Train loss: 316.532532\n",
      "Test loss: 202.413784\n",
      "\n",
      "[INFO] EPOCH: 628/1000\n",
      "Train loss: 282.057159\n",
      "Test loss: 201.644740\n",
      "\n",
      "[INFO] EPOCH: 629/1000\n",
      "Train loss: 282.555969\n",
      "Test loss: 202.194989\n",
      "\n",
      "[INFO] EPOCH: 630/1000\n",
      "Train loss: 289.549011\n",
      "Test loss: 202.600032\n",
      "\n",
      "[INFO] EPOCH: 631/1000\n",
      "Train loss: 283.311371\n",
      "Test loss: 202.948279\n",
      "\n",
      "[INFO] EPOCH: 632/1000\n",
      "Train loss: 277.040588\n",
      "Test loss: 202.981396\n",
      "\n",
      "[INFO] EPOCH: 633/1000\n",
      "Train loss: 282.503021\n",
      "Test loss: 203.161180\n",
      "\n",
      "[INFO] EPOCH: 634/1000\n",
      "Train loss: 288.425354\n",
      "Test loss: 202.248726\n",
      "\n",
      "[INFO] EPOCH: 635/1000\n",
      "Train loss: 288.963989\n",
      "Test loss: 202.298055\n",
      "\n",
      "[INFO] EPOCH: 636/1000\n",
      "Train loss: 319.972076\n",
      "Test loss: 202.976350\n",
      "\n",
      "[INFO] EPOCH: 637/1000\n",
      "Train loss: 294.108215\n",
      "Test loss: 201.955607\n",
      "\n",
      "[INFO] EPOCH: 638/1000\n",
      "Train loss: 278.532745\n",
      "Test loss: 202.875298\n",
      "\n",
      "[INFO] EPOCH: 639/1000\n",
      "Train loss: 307.278503\n",
      "Test loss: 202.967441\n",
      "\n",
      "[INFO] EPOCH: 640/1000\n",
      "Train loss: 300.869537\n",
      "Test loss: 202.221721\n",
      "\n",
      "[INFO] EPOCH: 641/1000\n",
      "Train loss: 302.399109\n",
      "Test loss: 202.557112\n",
      "\n",
      "[INFO] EPOCH: 642/1000\n",
      "Train loss: 265.784912\n",
      "Test loss: 201.641721\n",
      "\n",
      "[INFO] EPOCH: 643/1000\n",
      "Train loss: 274.523163\n",
      "Test loss: 201.032150\n",
      "\n",
      "[INFO] EPOCH: 644/1000\n",
      "Train loss: 291.348053\n",
      "Test loss: 200.820664\n",
      "\n",
      "[INFO] EPOCH: 645/1000\n",
      "Train loss: 286.936646\n",
      "Test loss: 200.880969\n",
      "\n",
      "[INFO] EPOCH: 646/1000\n",
      "Train loss: 331.037933\n",
      "Test loss: 201.599599\n",
      "\n",
      "[INFO] EPOCH: 647/1000\n",
      "Train loss: 293.412781\n",
      "Test loss: 202.490239\n",
      "\n",
      "[INFO] EPOCH: 648/1000\n",
      "Train loss: 311.597778\n",
      "Test loss: 202.402263\n",
      "\n",
      "[INFO] EPOCH: 649/1000\n",
      "Train loss: 299.651947\n",
      "Test loss: 202.970150\n",
      "\n",
      "[INFO] EPOCH: 650/1000\n",
      "Train loss: 303.464447\n",
      "Test loss: 202.559704\n",
      "\n",
      "[INFO] EPOCH: 651/1000\n",
      "Train loss: 297.177948\n",
      "Test loss: 202.903681\n",
      "\n",
      "[INFO] EPOCH: 652/1000\n",
      "Train loss: 322.865784\n",
      "Test loss: 203.424188\n",
      "\n",
      "[INFO] EPOCH: 653/1000\n",
      "Train loss: 281.762512\n",
      "Test loss: 202.082700\n",
      "\n",
      "[INFO] EPOCH: 654/1000\n",
      "Train loss: 287.955200\n",
      "Test loss: 202.144953\n",
      "\n",
      "[INFO] EPOCH: 655/1000\n",
      "Train loss: 310.909851\n",
      "Test loss: 203.782814\n",
      "\n",
      "[INFO] EPOCH: 656/1000\n",
      "Train loss: 290.788269\n",
      "Test loss: 205.203146\n",
      "\n",
      "[INFO] EPOCH: 657/1000\n",
      "Train loss: 295.792145\n",
      "Test loss: 205.290416\n",
      "\n",
      "[INFO] EPOCH: 658/1000\n",
      "Train loss: 312.521484\n",
      "Test loss: 203.406172\n",
      "\n",
      "[INFO] EPOCH: 659/1000\n",
      "Train loss: 282.124756\n",
      "Test loss: 202.279534\n",
      "\n",
      "[INFO] EPOCH: 660/1000\n",
      "Train loss: 292.204926\n",
      "Test loss: 202.045938\n",
      "\n",
      "[INFO] EPOCH: 661/1000\n",
      "Train loss: 292.690796\n",
      "Test loss: 202.205822\n",
      "\n",
      "[INFO] EPOCH: 662/1000\n",
      "Train loss: 315.156830\n",
      "Test loss: 202.898784\n",
      "\n",
      "[INFO] EPOCH: 663/1000\n",
      "Train loss: 297.690918\n",
      "Test loss: 202.378552\n",
      "\n",
      "[INFO] EPOCH: 664/1000\n",
      "Train loss: 289.180237\n",
      "Test loss: 202.290510\n",
      "\n",
      "[INFO] EPOCH: 665/1000\n",
      "Train loss: 292.264374\n",
      "Test loss: 202.298916\n",
      "\n",
      "[INFO] EPOCH: 666/1000\n",
      "Train loss: 304.844147\n",
      "Test loss: 202.596701\n",
      "\n",
      "[INFO] EPOCH: 667/1000\n",
      "Train loss: 274.582550\n",
      "Test loss: 202.631320\n",
      "\n",
      "[INFO] EPOCH: 668/1000\n",
      "Train loss: 270.757904\n",
      "Test loss: 201.767057\n",
      "\n",
      "[INFO] EPOCH: 669/1000\n",
      "Train loss: 294.551544\n",
      "Test loss: 202.643166\n",
      "\n",
      "[INFO] EPOCH: 670/1000\n",
      "Train loss: 282.363037\n",
      "Test loss: 203.809205\n",
      "\n",
      "[INFO] EPOCH: 671/1000\n",
      "Train loss: 289.774658\n",
      "Test loss: 204.339324\n",
      "\n",
      "[INFO] EPOCH: 672/1000\n",
      "Train loss: 283.194580\n",
      "Test loss: 203.940825\n",
      "\n",
      "[INFO] EPOCH: 673/1000\n",
      "Train loss: 293.776947\n",
      "Test loss: 204.468864\n",
      "\n",
      "[INFO] EPOCH: 674/1000\n",
      "Train loss: 297.303162\n",
      "Test loss: 204.273145\n",
      "\n",
      "[INFO] EPOCH: 675/1000\n",
      "Train loss: 279.930786\n",
      "Test loss: 203.664680\n",
      "\n",
      "[INFO] EPOCH: 676/1000\n",
      "Train loss: 294.562958\n",
      "Test loss: 203.455140\n",
      "\n",
      "[INFO] EPOCH: 677/1000\n",
      "Train loss: 318.175964\n",
      "Test loss: 202.596207\n",
      "\n",
      "[INFO] EPOCH: 678/1000\n",
      "Train loss: 305.064911\n",
      "Test loss: 204.186549\n",
      "\n",
      "[INFO] EPOCH: 679/1000\n",
      "Train loss: 306.887238\n",
      "Test loss: 203.390250\n",
      "\n",
      "[INFO] EPOCH: 680/1000\n",
      "Train loss: 273.181946\n",
      "Test loss: 203.615279\n",
      "\n",
      "[INFO] EPOCH: 681/1000\n",
      "Train loss: 291.253510\n",
      "Test loss: 204.045664\n",
      "\n",
      "[INFO] EPOCH: 682/1000\n",
      "Train loss: 296.375336\n",
      "Test loss: 204.523327\n",
      "\n",
      "[INFO] EPOCH: 683/1000\n",
      "Train loss: 304.180359\n",
      "Test loss: 204.234403\n",
      "\n",
      "[INFO] EPOCH: 684/1000\n",
      "Train loss: 284.798798\n",
      "Test loss: 204.273785\n",
      "\n",
      "[INFO] EPOCH: 685/1000\n",
      "Train loss: 306.146301\n",
      "Test loss: 204.433367\n",
      "\n",
      "[INFO] EPOCH: 686/1000\n",
      "Train loss: 287.806885\n",
      "Test loss: 202.835073\n",
      "\n",
      "[INFO] EPOCH: 687/1000\n",
      "Train loss: 279.013275\n",
      "Test loss: 203.212978\n",
      "\n",
      "[INFO] EPOCH: 688/1000\n",
      "Train loss: 292.834991\n",
      "Test loss: 202.116638\n",
      "\n",
      "[INFO] EPOCH: 689/1000\n",
      "Train loss: 295.890930\n",
      "Test loss: 201.604221\n",
      "\n",
      "[INFO] EPOCH: 690/1000\n",
      "Train loss: 285.007446\n",
      "Test loss: 201.940789\n",
      "\n",
      "[INFO] EPOCH: 691/1000\n",
      "Train loss: 284.563873\n",
      "Test loss: 202.135826\n",
      "\n",
      "[INFO] EPOCH: 692/1000\n",
      "Train loss: 317.145721\n",
      "Test loss: 203.569326\n",
      "\n",
      "[INFO] EPOCH: 693/1000\n",
      "Train loss: 340.454285\n",
      "Test loss: 203.768389\n",
      "\n",
      "[INFO] EPOCH: 694/1000\n",
      "Train loss: 277.331787\n",
      "Test loss: 205.581341\n",
      "\n",
      "[INFO] EPOCH: 695/1000\n",
      "Train loss: 291.590790\n",
      "Test loss: 206.225634\n",
      "\n",
      "[INFO] EPOCH: 696/1000\n",
      "Train loss: 271.724548\n",
      "Test loss: 204.376303\n",
      "\n",
      "[INFO] EPOCH: 697/1000\n",
      "Train loss: 292.042633\n",
      "Test loss: 204.041247\n",
      "\n",
      "[INFO] EPOCH: 698/1000\n",
      "Train loss: 296.688263\n",
      "Test loss: 204.813965\n",
      "\n",
      "[INFO] EPOCH: 699/1000\n",
      "Train loss: 290.912842\n",
      "Test loss: 203.607964\n",
      "\n",
      "[INFO] EPOCH: 700/1000\n",
      "Train loss: 301.429108\n",
      "Test loss: 203.348767\n",
      "\n",
      "[INFO] EPOCH: 701/1000\n",
      "Train loss: 270.554932\n",
      "Test loss: 203.829998\n",
      "\n",
      "[INFO] EPOCH: 702/1000\n",
      "Train loss: 329.430634\n",
      "Test loss: 203.695941\n",
      "\n",
      "[INFO] EPOCH: 703/1000\n",
      "Train loss: 299.987854\n",
      "Test loss: 202.719665\n",
      "\n",
      "[INFO] EPOCH: 704/1000\n",
      "Train loss: 290.630981\n",
      "Test loss: 203.928655\n",
      "\n",
      "[INFO] EPOCH: 705/1000\n",
      "Train loss: 287.856049\n",
      "Test loss: 203.935298\n",
      "\n",
      "[INFO] EPOCH: 706/1000\n",
      "Train loss: 301.694550\n",
      "Test loss: 203.712765\n",
      "\n",
      "[INFO] EPOCH: 707/1000\n",
      "Train loss: 302.762756\n",
      "Test loss: 206.004464\n",
      "\n",
      "[INFO] EPOCH: 708/1000\n",
      "Train loss: 322.031281\n",
      "Test loss: 206.254887\n",
      "\n",
      "[INFO] EPOCH: 709/1000\n",
      "Train loss: 311.707001\n",
      "Test loss: 204.173803\n",
      "\n",
      "[INFO] EPOCH: 710/1000\n",
      "Train loss: 282.085510\n",
      "Test loss: 202.960249\n",
      "\n",
      "[INFO] EPOCH: 711/1000\n",
      "Train loss: 277.939178\n",
      "Test loss: 203.877483\n",
      "\n",
      "[INFO] EPOCH: 712/1000\n",
      "Train loss: 279.110535\n",
      "Test loss: 203.932681\n",
      "\n",
      "[INFO] EPOCH: 713/1000\n",
      "Train loss: 274.238647\n",
      "Test loss: 204.870684\n",
      "\n",
      "[INFO] EPOCH: 714/1000\n",
      "Train loss: 308.344391\n",
      "Test loss: 204.434232\n",
      "\n",
      "[INFO] EPOCH: 715/1000\n",
      "Train loss: 277.500488\n",
      "Test loss: 203.590308\n",
      "\n",
      "[INFO] EPOCH: 716/1000\n",
      "Train loss: 295.815735\n",
      "Test loss: 203.680576\n",
      "\n",
      "[INFO] EPOCH: 717/1000\n",
      "Train loss: 276.088074\n",
      "Test loss: 203.807823\n",
      "\n",
      "[INFO] EPOCH: 718/1000\n",
      "Train loss: 298.013611\n",
      "Test loss: 204.747658\n",
      "\n",
      "[INFO] EPOCH: 719/1000\n",
      "Train loss: 294.163879\n",
      "Test loss: 204.925849\n",
      "\n",
      "[INFO] EPOCH: 720/1000\n",
      "Train loss: 269.003876\n",
      "Test loss: 204.436059\n",
      "\n",
      "[INFO] EPOCH: 721/1000\n",
      "Train loss: 292.658386\n",
      "Test loss: 204.298996\n",
      "\n",
      "[INFO] EPOCH: 722/1000\n",
      "Train loss: 272.725006\n",
      "Test loss: 203.671469\n",
      "\n",
      "[INFO] EPOCH: 723/1000\n",
      "Train loss: 291.314911\n",
      "Test loss: 203.096881\n",
      "\n",
      "[INFO] EPOCH: 724/1000\n",
      "Train loss: 335.602875\n",
      "Test loss: 203.847259\n",
      "\n",
      "[INFO] EPOCH: 725/1000\n",
      "Train loss: 282.288818\n",
      "Test loss: 203.248923\n",
      "\n",
      "[INFO] EPOCH: 726/1000\n",
      "Train loss: 297.068451\n",
      "Test loss: 202.384677\n",
      "\n",
      "[INFO] EPOCH: 727/1000\n",
      "Train loss: 293.161346\n",
      "Test loss: 203.338680\n",
      "\n",
      "[INFO] EPOCH: 728/1000\n",
      "Train loss: 317.182709\n",
      "Test loss: 203.589597\n",
      "\n",
      "[INFO] EPOCH: 729/1000\n",
      "Train loss: 281.284760\n",
      "Test loss: 203.440649\n",
      "\n",
      "[INFO] EPOCH: 730/1000\n",
      "Train loss: 306.354309\n",
      "Test loss: 204.776849\n",
      "\n",
      "[INFO] EPOCH: 731/1000\n",
      "Train loss: 284.173767\n",
      "Test loss: 203.652404\n",
      "\n",
      "[INFO] EPOCH: 732/1000\n",
      "Train loss: 321.031891\n",
      "Test loss: 202.790403\n",
      "\n",
      "[INFO] EPOCH: 733/1000\n",
      "Train loss: 293.837769\n",
      "Test loss: 203.342856\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] EPOCH: 734/1000\n",
      "Train loss: 283.810669\n",
      "Test loss: 204.590914\n",
      "\n",
      "[INFO] EPOCH: 735/1000\n",
      "Train loss: 292.556091\n",
      "Test loss: 204.211703\n",
      "\n",
      "[INFO] EPOCH: 736/1000\n",
      "Train loss: 276.505127\n",
      "Test loss: 205.002826\n",
      "\n",
      "[INFO] EPOCH: 737/1000\n",
      "Train loss: 271.153229\n",
      "Test loss: 204.665037\n",
      "\n",
      "[INFO] EPOCH: 738/1000\n",
      "Train loss: 274.749695\n",
      "Test loss: 203.396605\n",
      "\n",
      "[INFO] EPOCH: 739/1000\n",
      "Train loss: 281.880615\n",
      "Test loss: 205.176490\n",
      "\n",
      "[INFO] EPOCH: 740/1000\n",
      "Train loss: 272.952332\n",
      "Test loss: 205.077352\n",
      "\n",
      "[INFO] EPOCH: 741/1000\n",
      "Train loss: 285.557312\n",
      "Test loss: 204.561773\n",
      "\n",
      "[INFO] EPOCH: 742/1000\n",
      "Train loss: 342.020599\n",
      "Test loss: 204.424233\n",
      "\n",
      "[INFO] EPOCH: 743/1000\n",
      "Train loss: 312.593689\n",
      "Test loss: 204.182192\n",
      "\n",
      "[INFO] EPOCH: 744/1000\n",
      "Train loss: 289.383972\n",
      "Test loss: 205.485657\n",
      "\n",
      "[INFO] EPOCH: 745/1000\n",
      "Train loss: 286.158295\n",
      "Test loss: 205.758214\n",
      "\n",
      "[INFO] EPOCH: 746/1000\n",
      "Train loss: 308.774841\n",
      "Test loss: 205.823537\n",
      "\n",
      "[INFO] EPOCH: 747/1000\n",
      "Train loss: 286.534210\n",
      "Test loss: 205.891073\n",
      "\n",
      "[INFO] EPOCH: 748/1000\n",
      "Train loss: 271.522980\n",
      "Test loss: 205.761578\n",
      "\n",
      "[INFO] EPOCH: 749/1000\n",
      "Train loss: 272.872589\n",
      "Test loss: 204.942813\n",
      "\n",
      "[INFO] EPOCH: 750/1000\n",
      "Train loss: 272.246460\n",
      "Test loss: 205.918615\n",
      "\n",
      "[INFO] EPOCH: 751/1000\n",
      "Train loss: 279.934540\n",
      "Test loss: 207.082940\n",
      "\n",
      "[INFO] EPOCH: 752/1000\n",
      "Train loss: 285.312256\n",
      "Test loss: 206.292350\n",
      "\n",
      "[INFO] EPOCH: 753/1000\n",
      "Train loss: 286.339111\n",
      "Test loss: 207.528342\n",
      "\n",
      "[INFO] EPOCH: 754/1000\n",
      "Train loss: 281.379089\n",
      "Test loss: 207.895659\n",
      "\n",
      "[INFO] EPOCH: 755/1000\n",
      "Train loss: 287.391632\n",
      "Test loss: 207.325787\n",
      "\n",
      "[INFO] EPOCH: 756/1000\n",
      "Train loss: 276.104187\n",
      "Test loss: 206.099631\n",
      "\n",
      "[INFO] EPOCH: 757/1000\n",
      "Train loss: 284.369446\n",
      "Test loss: 205.804413\n",
      "\n",
      "[INFO] EPOCH: 758/1000\n",
      "Train loss: 280.912048\n",
      "Test loss: 205.803443\n",
      "\n",
      "[INFO] EPOCH: 759/1000\n",
      "Train loss: 281.549683\n",
      "Test loss: 205.782814\n",
      "\n",
      "[INFO] EPOCH: 760/1000\n",
      "Train loss: 316.945709\n",
      "Test loss: 205.912499\n",
      "\n",
      "[INFO] EPOCH: 761/1000\n",
      "Train loss: 301.835663\n",
      "Test loss: 205.916643\n",
      "\n",
      "[INFO] EPOCH: 762/1000\n",
      "Train loss: 321.010040\n",
      "Test loss: 205.863858\n",
      "\n",
      "[INFO] EPOCH: 763/1000\n",
      "Train loss: 277.960693\n",
      "Test loss: 207.973387\n",
      "\n",
      "[INFO] EPOCH: 764/1000\n",
      "Train loss: 301.023438\n",
      "Test loss: 208.947019\n",
      "\n",
      "[INFO] EPOCH: 765/1000\n",
      "Train loss: 275.153839\n",
      "Test loss: 208.554755\n",
      "\n",
      "[INFO] EPOCH: 766/1000\n",
      "Train loss: 289.975555\n",
      "Test loss: 208.328834\n",
      "\n",
      "[INFO] EPOCH: 767/1000\n",
      "Train loss: 279.054779\n",
      "Test loss: 207.002465\n",
      "\n",
      "[INFO] EPOCH: 768/1000\n",
      "Train loss: 297.183594\n",
      "Test loss: 207.593309\n",
      "\n",
      "[INFO] EPOCH: 769/1000\n",
      "Train loss: 275.809540\n",
      "Test loss: 206.473399\n",
      "\n",
      "[INFO] EPOCH: 770/1000\n",
      "Train loss: 286.736298\n",
      "Test loss: 206.656875\n",
      "\n",
      "[INFO] EPOCH: 771/1000\n",
      "Train loss: 301.558075\n",
      "Test loss: 206.445539\n",
      "\n",
      "[INFO] EPOCH: 772/1000\n",
      "Train loss: 282.244232\n",
      "Test loss: 206.523486\n",
      "\n",
      "[INFO] EPOCH: 773/1000\n",
      "Train loss: 294.011200\n",
      "Test loss: 206.916222\n",
      "\n",
      "[INFO] EPOCH: 774/1000\n",
      "Train loss: 285.546783\n",
      "Test loss: 207.404450\n",
      "\n",
      "[INFO] EPOCH: 775/1000\n",
      "Train loss: 289.947723\n",
      "Test loss: 207.950305\n",
      "\n",
      "[INFO] EPOCH: 776/1000\n",
      "Train loss: 277.715973\n",
      "Test loss: 207.672785\n",
      "\n",
      "[INFO] EPOCH: 777/1000\n",
      "Train loss: 283.809875\n",
      "Test loss: 208.642312\n",
      "\n",
      "[INFO] EPOCH: 778/1000\n",
      "Train loss: 309.669739\n",
      "Test loss: 209.186813\n",
      "\n",
      "[INFO] EPOCH: 779/1000\n",
      "Train loss: 291.630035\n",
      "Test loss: 207.127479\n",
      "\n",
      "[INFO] EPOCH: 780/1000\n",
      "Train loss: 264.054901\n",
      "Test loss: 207.182653\n",
      "\n",
      "[INFO] EPOCH: 781/1000\n",
      "Train loss: 301.071594\n",
      "Test loss: 206.047364\n",
      "\n",
      "[INFO] EPOCH: 782/1000\n",
      "Train loss: 308.661560\n",
      "Test loss: 207.560821\n",
      "\n",
      "[INFO] EPOCH: 783/1000\n",
      "Train loss: 287.875122\n",
      "Test loss: 208.888486\n",
      "\n",
      "[INFO] EPOCH: 784/1000\n",
      "Train loss: 276.253876\n",
      "Test loss: 209.473510\n",
      "\n",
      "[INFO] EPOCH: 785/1000\n",
      "Train loss: 269.142273\n",
      "Test loss: 209.332502\n",
      "\n",
      "[INFO] EPOCH: 786/1000\n",
      "Train loss: 270.134186\n",
      "Test loss: 207.830167\n",
      "\n",
      "[INFO] EPOCH: 787/1000\n",
      "Train loss: 269.549805\n",
      "Test loss: 206.196651\n",
      "\n",
      "[INFO] EPOCH: 788/1000\n",
      "Train loss: 289.947662\n",
      "Test loss: 206.787145\n",
      "\n",
      "[INFO] EPOCH: 789/1000\n",
      "Train loss: 283.289490\n",
      "Test loss: 204.972413\n",
      "\n",
      "[INFO] EPOCH: 790/1000\n",
      "Train loss: 300.047455\n",
      "Test loss: 204.958874\n",
      "\n",
      "[INFO] EPOCH: 791/1000\n",
      "Train loss: 295.155823\n",
      "Test loss: 204.368463\n",
      "\n",
      "[INFO] EPOCH: 792/1000\n",
      "Train loss: 280.774384\n",
      "Test loss: 204.702676\n",
      "\n",
      "[INFO] EPOCH: 793/1000\n",
      "Train loss: 318.184418\n",
      "Test loss: 205.178762\n",
      "\n",
      "[INFO] EPOCH: 794/1000\n",
      "Train loss: 278.673401\n",
      "Test loss: 204.480236\n",
      "\n",
      "[INFO] EPOCH: 795/1000\n",
      "Train loss: 299.983917\n",
      "Test loss: 206.069230\n",
      "\n",
      "[INFO] EPOCH: 796/1000\n",
      "Train loss: 283.410339\n",
      "Test loss: 205.504087\n",
      "\n",
      "[INFO] EPOCH: 797/1000\n",
      "Train loss: 287.753448\n",
      "Test loss: 207.019385\n",
      "\n",
      "[INFO] EPOCH: 798/1000\n",
      "Train loss: 269.365753\n",
      "Test loss: 207.352019\n",
      "\n",
      "[INFO] EPOCH: 799/1000\n",
      "Train loss: 265.671082\n",
      "Test loss: 208.401960\n",
      "\n",
      "[INFO] EPOCH: 800/1000\n",
      "Train loss: 283.426666\n",
      "Test loss: 206.717258\n",
      "\n",
      "[INFO] EPOCH: 801/1000\n",
      "Train loss: 294.868530\n",
      "Test loss: 205.398877\n",
      "\n",
      "[INFO] EPOCH: 802/1000\n",
      "Train loss: 280.527069\n",
      "Test loss: 204.578871\n",
      "\n",
      "[INFO] EPOCH: 803/1000\n",
      "Train loss: 284.199219\n",
      "Test loss: 205.411349\n",
      "\n",
      "[INFO] EPOCH: 804/1000\n",
      "Train loss: 266.564789\n",
      "Test loss: 205.456707\n",
      "\n",
      "[INFO] EPOCH: 805/1000\n",
      "Train loss: 270.409363\n",
      "Test loss: 206.286686\n",
      "\n",
      "[INFO] EPOCH: 806/1000\n",
      "Train loss: 290.584900\n",
      "Test loss: 205.564702\n",
      "\n",
      "[INFO] EPOCH: 807/1000\n",
      "Train loss: 291.948273\n",
      "Test loss: 205.793846\n",
      "\n",
      "[INFO] EPOCH: 808/1000\n",
      "Train loss: 282.771362\n",
      "Test loss: 205.994816\n",
      "\n",
      "[INFO] EPOCH: 809/1000\n",
      "Train loss: 290.929871\n",
      "Test loss: 206.071888\n",
      "\n",
      "[INFO] EPOCH: 810/1000\n",
      "Train loss: 280.952271\n",
      "Test loss: 205.142014\n",
      "\n",
      "[INFO] EPOCH: 811/1000\n",
      "Train loss: 283.684967\n",
      "Test loss: 207.365581\n",
      "\n",
      "[INFO] EPOCH: 812/1000\n",
      "Train loss: 276.297607\n",
      "Test loss: 207.797465\n",
      "\n",
      "[INFO] EPOCH: 813/1000\n",
      "Train loss: 281.842133\n",
      "Test loss: 209.082715\n",
      "\n",
      "[INFO] EPOCH: 814/1000\n",
      "Train loss: 299.402191\n",
      "Test loss: 208.450540\n",
      "\n",
      "[INFO] EPOCH: 815/1000\n",
      "Train loss: 289.454254\n",
      "Test loss: 209.757569\n",
      "\n",
      "[INFO] EPOCH: 816/1000\n",
      "Train loss: 288.095520\n",
      "Test loss: 209.403639\n",
      "\n",
      "[INFO] EPOCH: 817/1000\n",
      "Train loss: 309.193878\n",
      "Test loss: 208.201228\n",
      "\n",
      "[INFO] EPOCH: 818/1000\n",
      "Train loss: 293.454620\n",
      "Test loss: 209.463265\n",
      "\n",
      "[INFO] EPOCH: 819/1000\n",
      "Train loss: 282.120239\n",
      "Test loss: 211.039484\n",
      "\n",
      "[INFO] EPOCH: 820/1000\n",
      "Train loss: 296.865479\n",
      "Test loss: 209.646161\n",
      "\n",
      "[INFO] EPOCH: 821/1000\n",
      "Train loss: 293.507446\n",
      "Test loss: 209.140210\n",
      "\n",
      "[INFO] EPOCH: 822/1000\n",
      "Train loss: 282.459900\n",
      "Test loss: 206.311668\n",
      "\n",
      "[INFO] EPOCH: 823/1000\n",
      "Train loss: 265.931396\n",
      "Test loss: 206.911654\n",
      "\n",
      "[INFO] EPOCH: 824/1000\n",
      "Train loss: 304.139496\n",
      "Test loss: 207.421612\n",
      "\n",
      "[INFO] EPOCH: 825/1000\n",
      "Train loss: 265.382263\n",
      "Test loss: 206.811675\n",
      "\n",
      "[INFO] EPOCH: 826/1000\n",
      "Train loss: 276.670166\n",
      "Test loss: 208.177493\n",
      "\n",
      "[INFO] EPOCH: 827/1000\n",
      "Train loss: 285.368683\n",
      "Test loss: 207.148060\n",
      "\n",
      "[INFO] EPOCH: 828/1000\n",
      "Train loss: 273.533752\n",
      "Test loss: 209.092364\n",
      "\n",
      "[INFO] EPOCH: 829/1000\n",
      "Train loss: 293.537384\n",
      "Test loss: 209.361563\n",
      "\n",
      "[INFO] EPOCH: 830/1000\n",
      "Train loss: 279.477661\n",
      "Test loss: 207.838923\n",
      "\n",
      "[INFO] EPOCH: 831/1000\n",
      "Train loss: 278.482849\n",
      "Test loss: 208.387262\n",
      "\n",
      "[INFO] EPOCH: 832/1000\n",
      "Train loss: 260.104828\n",
      "Test loss: 208.060618\n",
      "\n",
      "[INFO] EPOCH: 833/1000\n",
      "Train loss: 273.781738\n",
      "Test loss: 210.018749\n",
      "\n",
      "[INFO] EPOCH: 834/1000\n",
      "Train loss: 350.946533\n",
      "Test loss: 207.494570\n",
      "\n",
      "[INFO] EPOCH: 835/1000\n",
      "Train loss: 292.898956\n",
      "Test loss: 206.600107\n",
      "\n",
      "[INFO] EPOCH: 836/1000\n",
      "Train loss: 263.643585\n",
      "Test loss: 210.099739\n",
      "\n",
      "[INFO] EPOCH: 837/1000\n",
      "Train loss: 273.729340\n",
      "Test loss: 210.009590\n",
      "\n",
      "[INFO] EPOCH: 838/1000\n",
      "Train loss: 287.501373\n",
      "Test loss: 209.041667\n",
      "\n",
      "[INFO] EPOCH: 839/1000\n",
      "Train loss: 293.396179\n",
      "Test loss: 209.239610\n",
      "\n",
      "[INFO] EPOCH: 840/1000\n",
      "Train loss: 302.270752\n",
      "Test loss: 208.090690\n",
      "\n",
      "[INFO] EPOCH: 841/1000\n",
      "Train loss: 262.421570\n",
      "Test loss: 210.266495\n",
      "\n",
      "[INFO] EPOCH: 842/1000\n",
      "Train loss: 288.820831\n",
      "Test loss: 210.516567\n",
      "\n",
      "[INFO] EPOCH: 843/1000\n",
      "Train loss: 259.030182\n",
      "Test loss: 210.606916\n",
      "\n",
      "[INFO] EPOCH: 844/1000\n",
      "Train loss: 273.530823\n",
      "Test loss: 211.059017\n",
      "\n",
      "[INFO] EPOCH: 845/1000\n",
      "Train loss: 254.564987\n",
      "Test loss: 212.119984\n",
      "\n",
      "[INFO] EPOCH: 846/1000\n",
      "Train loss: 302.947998\n",
      "Test loss: 212.107348\n",
      "\n",
      "[INFO] EPOCH: 847/1000\n",
      "Train loss: 279.379913\n",
      "Test loss: 211.385704\n",
      "\n",
      "[INFO] EPOCH: 848/1000\n",
      "Train loss: 276.256958\n",
      "Test loss: 210.495255\n",
      "\n",
      "[INFO] EPOCH: 849/1000\n",
      "Train loss: 280.802826\n",
      "Test loss: 209.669515\n",
      "\n",
      "[INFO] EPOCH: 850/1000\n",
      "Train loss: 311.596130\n",
      "Test loss: 209.847054\n",
      "\n",
      "[INFO] EPOCH: 851/1000\n",
      "Train loss: 320.322693\n",
      "Test loss: 208.141959\n",
      "\n",
      "[INFO] EPOCH: 852/1000\n",
      "Train loss: 296.565063\n",
      "Test loss: 207.518106\n",
      "\n",
      "[INFO] EPOCH: 853/1000\n",
      "Train loss: 275.606049\n",
      "Test loss: 206.650267\n",
      "\n",
      "[INFO] EPOCH: 854/1000\n",
      "Train loss: 289.790192\n",
      "Test loss: 205.997122\n",
      "\n",
      "[INFO] EPOCH: 855/1000\n",
      "Train loss: 273.226685\n",
      "Test loss: 207.583167\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] EPOCH: 856/1000\n",
      "Train loss: 287.084290\n",
      "Test loss: 208.396684\n",
      "\n",
      "[INFO] EPOCH: 857/1000\n",
      "Train loss: 281.219696\n",
      "Test loss: 208.503885\n",
      "\n",
      "[INFO] EPOCH: 858/1000\n",
      "Train loss: 292.760437\n",
      "Test loss: 208.849567\n",
      "\n",
      "[INFO] EPOCH: 859/1000\n",
      "Train loss: 256.215820\n",
      "Test loss: 206.395945\n",
      "\n",
      "[INFO] EPOCH: 860/1000\n",
      "Train loss: 295.991882\n",
      "Test loss: 204.889434\n",
      "\n",
      "[INFO] EPOCH: 861/1000\n",
      "Train loss: 266.560028\n",
      "Test loss: 205.708501\n",
      "\n",
      "[INFO] EPOCH: 862/1000\n",
      "Train loss: 263.594879\n",
      "Test loss: 205.596798\n",
      "\n",
      "[INFO] EPOCH: 863/1000\n",
      "Train loss: 283.477234\n",
      "Test loss: 205.539378\n",
      "\n",
      "[INFO] EPOCH: 864/1000\n",
      "Train loss: 281.859253\n",
      "Test loss: 205.570158\n",
      "\n",
      "[INFO] EPOCH: 865/1000\n",
      "Train loss: 300.909546\n",
      "Test loss: 207.558950\n",
      "\n",
      "[INFO] EPOCH: 866/1000\n",
      "Train loss: 291.191956\n",
      "Test loss: 210.086631\n",
      "\n",
      "[INFO] EPOCH: 867/1000\n",
      "Train loss: 281.949738\n",
      "Test loss: 209.792857\n",
      "\n",
      "[INFO] EPOCH: 868/1000\n",
      "Train loss: 278.898376\n",
      "Test loss: 208.743397\n",
      "\n",
      "[INFO] EPOCH: 869/1000\n",
      "Train loss: 298.313690\n",
      "Test loss: 211.944344\n",
      "\n",
      "[INFO] EPOCH: 870/1000\n",
      "Train loss: 259.169952\n",
      "Test loss: 208.650164\n",
      "\n",
      "[INFO] EPOCH: 871/1000\n",
      "Train loss: 308.329651\n",
      "Test loss: 209.727238\n",
      "\n",
      "[INFO] EPOCH: 872/1000\n",
      "Train loss: 275.335968\n",
      "Test loss: 209.512565\n",
      "\n",
      "[INFO] EPOCH: 873/1000\n",
      "Train loss: 264.275299\n",
      "Test loss: 211.216310\n",
      "\n",
      "[INFO] EPOCH: 874/1000\n",
      "Train loss: 296.738373\n",
      "Test loss: 210.570469\n",
      "\n",
      "[INFO] EPOCH: 875/1000\n",
      "Train loss: 270.815216\n",
      "Test loss: 211.014651\n",
      "\n",
      "[INFO] EPOCH: 876/1000\n",
      "Train loss: 276.866302\n",
      "Test loss: 209.975771\n",
      "\n",
      "[INFO] EPOCH: 877/1000\n",
      "Train loss: 273.966858\n",
      "Test loss: 209.321980\n",
      "\n",
      "[INFO] EPOCH: 878/1000\n",
      "Train loss: 287.947845\n",
      "Test loss: 209.819774\n",
      "\n",
      "[INFO] EPOCH: 879/1000\n",
      "Train loss: 280.586151\n",
      "Test loss: 210.931863\n",
      "\n",
      "[INFO] EPOCH: 880/1000\n",
      "Train loss: 272.940369\n",
      "Test loss: 213.019715\n",
      "\n",
      "[INFO] EPOCH: 881/1000\n",
      "Train loss: 286.024933\n",
      "Test loss: 211.112156\n",
      "\n",
      "[INFO] EPOCH: 882/1000\n",
      "Train loss: 266.149017\n",
      "Test loss: 210.533732\n",
      "\n",
      "[INFO] EPOCH: 883/1000\n",
      "Train loss: 265.947784\n",
      "Test loss: 208.410593\n",
      "\n",
      "[INFO] EPOCH: 884/1000\n",
      "Train loss: 281.786377\n",
      "Test loss: 209.277012\n",
      "\n",
      "[INFO] EPOCH: 885/1000\n",
      "Train loss: 275.000458\n",
      "Test loss: 208.760218\n",
      "\n",
      "[INFO] EPOCH: 886/1000\n",
      "Train loss: 274.136444\n",
      "Test loss: 211.198996\n",
      "\n",
      "[INFO] EPOCH: 887/1000\n",
      "Train loss: 275.440582\n",
      "Test loss: 211.454686\n",
      "\n",
      "[INFO] EPOCH: 888/1000\n",
      "Train loss: 277.894653\n",
      "Test loss: 212.318105\n",
      "\n",
      "[INFO] EPOCH: 889/1000\n",
      "Train loss: 281.584595\n",
      "Test loss: 211.262526\n",
      "\n",
      "[INFO] EPOCH: 890/1000\n",
      "Train loss: 305.641144\n",
      "Test loss: 211.096278\n",
      "\n",
      "[INFO] EPOCH: 891/1000\n",
      "Train loss: 270.701202\n",
      "Test loss: 210.447806\n",
      "\n",
      "[INFO] EPOCH: 892/1000\n",
      "Train loss: 289.355835\n",
      "Test loss: 209.107696\n",
      "\n",
      "[INFO] EPOCH: 893/1000\n",
      "Train loss: 270.966064\n",
      "Test loss: 209.484124\n",
      "\n",
      "[INFO] EPOCH: 894/1000\n",
      "Train loss: 288.782593\n",
      "Test loss: 211.930949\n",
      "\n",
      "[INFO] EPOCH: 895/1000\n",
      "Train loss: 282.406708\n",
      "Test loss: 209.616328\n",
      "\n",
      "[INFO] EPOCH: 896/1000\n",
      "Train loss: 293.856689\n",
      "Test loss: 210.170919\n",
      "\n",
      "[INFO] EPOCH: 897/1000\n",
      "Train loss: 280.200378\n",
      "Test loss: 211.094581\n",
      "\n",
      "[INFO] EPOCH: 898/1000\n",
      "Train loss: 264.993561\n",
      "Test loss: 210.968831\n",
      "\n",
      "[INFO] EPOCH: 899/1000\n",
      "Train loss: 266.493134\n",
      "Test loss: 209.667295\n",
      "\n",
      "[INFO] EPOCH: 900/1000\n",
      "Train loss: 266.151062\n",
      "Test loss: 209.305333\n",
      "\n",
      "[INFO] EPOCH: 901/1000\n",
      "Train loss: 266.770966\n",
      "Test loss: 211.035671\n",
      "\n",
      "[INFO] EPOCH: 902/1000\n",
      "Train loss: 290.019043\n",
      "Test loss: 215.343001\n",
      "\n",
      "[INFO] EPOCH: 903/1000\n",
      "Train loss: 288.130005\n",
      "Test loss: 212.990296\n",
      "\n",
      "[INFO] EPOCH: 904/1000\n",
      "Train loss: 277.979126\n",
      "Test loss: 211.635428\n",
      "\n",
      "[INFO] EPOCH: 905/1000\n",
      "Train loss: 292.440369\n",
      "Test loss: 212.972475\n",
      "\n",
      "[INFO] EPOCH: 906/1000\n",
      "Train loss: 290.893707\n",
      "Test loss: 212.275963\n",
      "\n",
      "[INFO] EPOCH: 907/1000\n",
      "Train loss: 270.738373\n",
      "Test loss: 210.637260\n",
      "\n",
      "[INFO] EPOCH: 908/1000\n",
      "Train loss: 284.497955\n",
      "Test loss: 209.862616\n",
      "\n",
      "[INFO] EPOCH: 909/1000\n",
      "Train loss: 277.944794\n",
      "Test loss: 211.507899\n",
      "\n",
      "[INFO] EPOCH: 910/1000\n",
      "Train loss: 294.927338\n",
      "Test loss: 212.503174\n",
      "\n",
      "[INFO] EPOCH: 911/1000\n",
      "Train loss: 268.801575\n",
      "Test loss: 211.898222\n",
      "\n",
      "[INFO] EPOCH: 912/1000\n",
      "Train loss: 262.628418\n",
      "Test loss: 212.640285\n",
      "\n",
      "[INFO] EPOCH: 913/1000\n",
      "Train loss: 280.910492\n",
      "Test loss: 211.786513\n",
      "\n",
      "[INFO] EPOCH: 914/1000\n",
      "Train loss: 268.890167\n",
      "Test loss: 211.971192\n",
      "\n",
      "[INFO] EPOCH: 915/1000\n",
      "Train loss: 282.687805\n",
      "Test loss: 212.449959\n",
      "\n",
      "[INFO] EPOCH: 916/1000\n",
      "Train loss: 282.644012\n",
      "Test loss: 214.774816\n",
      "\n",
      "[INFO] EPOCH: 917/1000\n",
      "Train loss: 275.172485\n",
      "Test loss: 216.300366\n",
      "\n",
      "[INFO] EPOCH: 918/1000\n",
      "Train loss: 272.494751\n",
      "Test loss: 216.669425\n",
      "\n",
      "[INFO] EPOCH: 919/1000\n",
      "Train loss: 271.858673\n",
      "Test loss: 215.904723\n",
      "\n",
      "[INFO] EPOCH: 920/1000\n",
      "Train loss: 271.268372\n",
      "Test loss: 216.120756\n",
      "\n",
      "[INFO] EPOCH: 921/1000\n",
      "Train loss: 261.795410\n",
      "Test loss: 216.462443\n",
      "\n",
      "[INFO] EPOCH: 922/1000\n",
      "Train loss: 274.608887\n",
      "Test loss: 215.232956\n",
      "\n",
      "[INFO] EPOCH: 923/1000\n",
      "Train loss: 281.438202\n",
      "Test loss: 214.850106\n",
      "\n",
      "[INFO] EPOCH: 924/1000\n",
      "Train loss: 273.662994\n",
      "Test loss: 212.101694\n",
      "\n",
      "[INFO] EPOCH: 925/1000\n",
      "Train loss: 273.883911\n",
      "Test loss: 213.229965\n",
      "\n",
      "[INFO] EPOCH: 926/1000\n",
      "Train loss: 301.116882\n",
      "Test loss: 212.009009\n",
      "\n",
      "[INFO] EPOCH: 927/1000\n",
      "Train loss: 272.768372\n",
      "Test loss: 211.154452\n",
      "\n",
      "[INFO] EPOCH: 928/1000\n",
      "Train loss: 285.558655\n",
      "Test loss: 211.327065\n",
      "\n",
      "[INFO] EPOCH: 929/1000\n",
      "Train loss: 280.098328\n",
      "Test loss: 209.860486\n",
      "\n",
      "[INFO] EPOCH: 930/1000\n",
      "Train loss: 277.619080\n",
      "Test loss: 209.477344\n",
      "\n",
      "[INFO] EPOCH: 931/1000\n",
      "Train loss: 291.504272\n",
      "Test loss: 211.155235\n",
      "\n",
      "[INFO] EPOCH: 932/1000\n",
      "Train loss: 296.731079\n",
      "Test loss: 213.200773\n",
      "\n",
      "[INFO] EPOCH: 933/1000\n",
      "Train loss: 258.363068\n",
      "Test loss: 216.529126\n",
      "\n",
      "[INFO] EPOCH: 934/1000\n",
      "Train loss: 269.042877\n",
      "Test loss: 214.237973\n",
      "\n",
      "[INFO] EPOCH: 935/1000\n",
      "Train loss: 272.999329\n",
      "Test loss: 211.939676\n",
      "\n",
      "[INFO] EPOCH: 936/1000\n",
      "Train loss: 271.631073\n",
      "Test loss: 210.840083\n",
      "\n",
      "[INFO] EPOCH: 937/1000\n",
      "Train loss: 273.728912\n",
      "Test loss: 210.131690\n",
      "\n",
      "[INFO] EPOCH: 938/1000\n",
      "Train loss: 283.281677\n",
      "Test loss: 211.745708\n",
      "\n",
      "[INFO] EPOCH: 939/1000\n",
      "Train loss: 298.795044\n",
      "Test loss: 211.838095\n",
      "\n",
      "[INFO] EPOCH: 940/1000\n",
      "Train loss: 307.330658\n",
      "Test loss: 210.913706\n",
      "\n",
      "[INFO] EPOCH: 941/1000\n",
      "Train loss: 264.622864\n",
      "Test loss: 214.542371\n",
      "\n",
      "[INFO] EPOCH: 942/1000\n",
      "Train loss: 280.264893\n",
      "Test loss: 213.865616\n",
      "\n",
      "[INFO] EPOCH: 943/1000\n",
      "Train loss: 271.862213\n",
      "Test loss: 211.845553\n",
      "\n",
      "[INFO] EPOCH: 944/1000\n",
      "Train loss: 270.230225\n",
      "Test loss: 211.592521\n",
      "\n",
      "[INFO] EPOCH: 945/1000\n",
      "Train loss: 260.452148\n",
      "Test loss: 212.870196\n",
      "\n",
      "[INFO] EPOCH: 946/1000\n",
      "Train loss: 272.737976\n",
      "Test loss: 211.857417\n",
      "\n",
      "[INFO] EPOCH: 947/1000\n",
      "Train loss: 285.980164\n",
      "Test loss: 210.771560\n",
      "\n",
      "[INFO] EPOCH: 948/1000\n",
      "Train loss: 286.814880\n",
      "Test loss: 208.843082\n",
      "\n",
      "[INFO] EPOCH: 949/1000\n",
      "Train loss: 281.930450\n",
      "Test loss: 208.561447\n",
      "\n",
      "[INFO] EPOCH: 950/1000\n",
      "Train loss: 269.971466\n",
      "Test loss: 210.132641\n",
      "\n",
      "[INFO] EPOCH: 951/1000\n",
      "Train loss: 285.295959\n",
      "Test loss: 211.134208\n",
      "\n",
      "[INFO] EPOCH: 952/1000\n",
      "Train loss: 291.853973\n",
      "Test loss: 213.168103\n",
      "\n",
      "[INFO] EPOCH: 953/1000\n",
      "Train loss: 279.301331\n",
      "Test loss: 213.216476\n",
      "\n",
      "[INFO] EPOCH: 954/1000\n",
      "Train loss: 289.983337\n",
      "Test loss: 214.730269\n",
      "\n",
      "[INFO] EPOCH: 955/1000\n",
      "Train loss: 262.248474\n",
      "Test loss: 214.342868\n",
      "\n",
      "[INFO] EPOCH: 956/1000\n",
      "Train loss: 272.654053\n",
      "Test loss: 212.579008\n",
      "\n",
      "[INFO] EPOCH: 957/1000\n",
      "Train loss: 269.480377\n",
      "Test loss: 213.440258\n",
      "\n",
      "[INFO] EPOCH: 958/1000\n",
      "Train loss: 277.876282\n",
      "Test loss: 211.569552\n",
      "\n",
      "[INFO] EPOCH: 959/1000\n",
      "Train loss: 274.433929\n",
      "Test loss: 209.468831\n",
      "\n",
      "[INFO] EPOCH: 960/1000\n",
      "Train loss: 272.610840\n",
      "Test loss: 212.003810\n",
      "\n",
      "[INFO] EPOCH: 961/1000\n",
      "Train loss: 323.922943\n",
      "Test loss: 213.205708\n",
      "\n",
      "[INFO] EPOCH: 962/1000\n",
      "Train loss: 281.040131\n",
      "Test loss: 217.107542\n",
      "\n",
      "[INFO] EPOCH: 963/1000\n",
      "Train loss: 277.600739\n",
      "Test loss: 214.989976\n",
      "\n",
      "[INFO] EPOCH: 964/1000\n",
      "Train loss: 266.999146\n",
      "Test loss: 210.965514\n",
      "\n",
      "[INFO] EPOCH: 965/1000\n",
      "Train loss: 278.440552\n",
      "Test loss: 209.688751\n",
      "\n",
      "[INFO] EPOCH: 966/1000\n",
      "Train loss: 275.101135\n",
      "Test loss: 210.872876\n",
      "\n",
      "[INFO] EPOCH: 967/1000\n",
      "Train loss: 272.062042\n",
      "Test loss: 211.801594\n",
      "\n",
      "[INFO] EPOCH: 968/1000\n",
      "Train loss: 270.733307\n",
      "Test loss: 211.450790\n",
      "\n",
      "[INFO] EPOCH: 969/1000\n",
      "Train loss: 274.618744\n",
      "Test loss: 213.975412\n",
      "\n",
      "[INFO] EPOCH: 970/1000\n",
      "Train loss: 305.155182\n",
      "Test loss: 213.684954\n",
      "\n",
      "[INFO] EPOCH: 971/1000\n",
      "Train loss: 261.701935\n",
      "Test loss: 211.563751\n",
      "\n",
      "[INFO] EPOCH: 972/1000\n",
      "Train loss: 279.359283\n",
      "Test loss: 211.168393\n",
      "\n",
      "[INFO] EPOCH: 973/1000\n",
      "Train loss: 316.624878\n",
      "Test loss: 212.038584\n",
      "\n",
      "[INFO] EPOCH: 974/1000\n",
      "Train loss: 290.066650\n",
      "Test loss: 212.862177\n",
      "\n",
      "[INFO] EPOCH: 975/1000\n",
      "Train loss: 263.221558\n",
      "Test loss: 215.774583\n",
      "\n",
      "[INFO] EPOCH: 976/1000\n",
      "Train loss: 296.084503\n",
      "Test loss: 216.624621\n",
      "\n",
      "[INFO] EPOCH: 977/1000\n",
      "Train loss: 279.455322\n",
      "Test loss: 213.462319\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] EPOCH: 978/1000\n",
      "Train loss: 263.398193\n",
      "Test loss: 213.682314\n",
      "\n",
      "[INFO] EPOCH: 979/1000\n",
      "Train loss: 300.857544\n",
      "Test loss: 214.750511\n",
      "\n",
      "[INFO] EPOCH: 980/1000\n",
      "Train loss: 261.352173\n",
      "Test loss: 215.293347\n",
      "\n",
      "[INFO] EPOCH: 981/1000\n",
      "Train loss: 275.738739\n",
      "Test loss: 214.461477\n",
      "\n",
      "[INFO] EPOCH: 982/1000\n",
      "Train loss: 284.808624\n",
      "Test loss: 214.291360\n",
      "\n",
      "[INFO] EPOCH: 983/1000\n",
      "Train loss: 292.233063\n",
      "Test loss: 215.743840\n",
      "\n",
      "[INFO] EPOCH: 984/1000\n",
      "Train loss: 266.767761\n",
      "Test loss: 213.706972\n",
      "\n",
      "[INFO] EPOCH: 985/1000\n",
      "Train loss: 264.936615\n",
      "Test loss: 214.867499\n",
      "\n",
      "[INFO] EPOCH: 986/1000\n",
      "Train loss: 285.621399\n",
      "Test loss: 212.967822\n",
      "\n",
      "[INFO] EPOCH: 987/1000\n",
      "Train loss: 282.645599\n",
      "Test loss: 214.068923\n",
      "\n",
      "[INFO] EPOCH: 988/1000\n",
      "Train loss: 282.901398\n",
      "Test loss: 214.501793\n",
      "\n",
      "[INFO] EPOCH: 989/1000\n",
      "Train loss: 270.321106\n",
      "Test loss: 215.260271\n",
      "\n",
      "[INFO] EPOCH: 990/1000\n",
      "Train loss: 243.239532\n",
      "Test loss: 214.691002\n",
      "\n",
      "[INFO] EPOCH: 991/1000\n",
      "Train loss: 275.591064\n",
      "Test loss: 215.926865\n",
      "\n",
      "[INFO] EPOCH: 992/1000\n",
      "Train loss: 272.583679\n",
      "Test loss: 215.027531\n",
      "\n",
      "[INFO] EPOCH: 993/1000\n",
      "Train loss: 266.887024\n",
      "Test loss: 214.246100\n",
      "\n",
      "[INFO] EPOCH: 994/1000\n",
      "Train loss: 271.611725\n",
      "Test loss: 214.587664\n",
      "\n",
      "[INFO] EPOCH: 995/1000\n",
      "Train loss: 303.550323\n",
      "Test loss: 214.033769\n",
      "\n",
      "[INFO] EPOCH: 996/1000\n",
      "Train loss: 274.804321\n",
      "Test loss: 216.521597\n",
      "\n",
      "[INFO] EPOCH: 997/1000\n",
      "Train loss: 278.195892\n",
      "Test loss: 216.163030\n",
      "\n",
      "[INFO] EPOCH: 998/1000\n",
      "Train loss: 277.754791\n",
      "Test loss: 215.375085\n",
      "\n",
      "[INFO] EPOCH: 999/1000\n",
      "Train loss: 286.930267\n",
      "Test loss: 215.380872\n",
      "\n",
      "[INFO] EPOCH: 1000/1000\n",
      "Train loss: 245.613068\n",
      "Test loss: 214.791656\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import flatten\n",
    "from torch.nn import Conv2d, Linear, LogSoftmax, MaxPool2d, Module, ReLU\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "import time\n",
    "\n",
    "class yashvidataset(Dataset):\n",
    "    def __init__(self, path, train=True, split = 0.8):\n",
    "        df = pd.read_csv(path)\n",
    "        if train:\n",
    "            self.length = int(len(df) * split)\n",
    "            values = df.values[:self.length]\n",
    "        else:\n",
    "            self.training_length = int(len(df) * split)\n",
    "            values = df.values[self.training_length:]\n",
    "            self.length = len(df) - self.training_length\n",
    "\n",
    "        self.build_data(values)\n",
    "\n",
    "    def build_data(self, values):\n",
    "        self.X = []\n",
    "        self.Y = []\n",
    "\n",
    "        for value in values:\n",
    "            self.X.append(value[:len(value)-1])\n",
    "            self.Y.append(value[-1])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        feature = torch.FloatTensor(self.X[idx])\n",
    "        label = self.Y[idx]\n",
    "\n",
    "        return feature, label\n",
    "\n",
    "\n",
    "training_dataset = yashvidataset(\"save.csv\", train=True)\n",
    "testing_dataset = yashvidataset(\"save.csv\", train=False)\n",
    "\n",
    "BATCH_SIZE = 10\n",
    "\n",
    "train_dataloader = DataLoader(training_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = DataLoader(testing_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "trainSteps = len(train_dataloader.dataset) // BATCH_SIZE\n",
    "testSteps = len(test_dataloader.dataset) // BATCH_SIZE\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(25, 50) \n",
    "        self.drop1 = nn.Dropout(0.2)\n",
    "        self.fc2 = nn.Linear(50, 100)\n",
    "        self.drop2 = nn.Dropout(0.2)\n",
    "        self.fc3 = nn.Linear(100, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.drop1(F.relu(self.fc1(x)))\n",
    "        x = self.drop2(F.relu(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "INIT_LR = 1e-5\n",
    "EPOCHS = 1000\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = Net().to(device)\n",
    "\n",
    "\n",
    "opt = Adam(model.parameters(), lr=INIT_LR)\n",
    "lossFn = nn.MSELoss()\n",
    "H = {\n",
    "\"train_loss\": [],\n",
    "\"test_loss\": [],\n",
    "}\n",
    "\n",
    "print(\"[INFO] Training the network...\")\n",
    "startTime = time.time()\n",
    "\n",
    "\n",
    "for e in range(0, EPOCHS):\n",
    "    #training mode\n",
    "    model.train()\n",
    "\n",
    "    totalTrainLoss = 0\n",
    "    totalTestLoss = 0\n",
    "   \n",
    "    trainCorrect = 0\n",
    "    testCorrect = 0\n",
    "    \n",
    "    for (x, y) in train_dataloader:\n",
    "        (x, y) = (x.to(device), y.to(device))\n",
    "        \n",
    "        pred = model(x)\n",
    "        loss = lossFn(pred.float(), y.float())\n",
    "        # zero out the gradients, perform the backpropagation step,\n",
    "        # and update the weights\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        # loss to the total training loss \n",
    "        totalTrainLoss += loss\n",
    "\n",
    "    # switch off autograd for evaluation\n",
    "    with torch.no_grad():\n",
    "        # set the model in evaluation mode\n",
    "        model.eval()\n",
    "        # loop over the validation set\n",
    "        for (x, y) in test_dataloader:\n",
    "            # send the input to the device\n",
    "            (x, y) = (x.to(device), y.to(device))\n",
    "            # make the predictions and calculate the validation loss\n",
    "            pred = model(x)\n",
    "            totalTestLoss += lossFn(pred, y)\n",
    "            # calculate the number of correct predictions\n",
    "\n",
    "    # calculate the average training and validation loss\n",
    "    avgTrainLoss = totalTrainLoss / trainSteps\n",
    "    avgTestLoss = totalTestLoss / testSteps\n",
    "\n",
    "    # update our training history\n",
    "    H[\"train_loss\"].append(avgTrainLoss.cpu().detach().numpy())\n",
    "    H[\"test_loss\"].append(avgTestLoss.cpu().detach().numpy())\n",
    "    # print the model training and validation information\n",
    "    print(\"[INFO] EPOCH: {}/{}\".format(e + 1, EPOCHS))\n",
    "    print(\"Train loss: {:.6f}\".format(avgTrainLoss))\n",
    "    print(\"Test loss: {:.6f}\\n\".format(avgTestLoss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "formal-personality",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[84.8456],\n",
      "        [93.5064],\n",
      "        [78.3952]]) tensor([97., 81., 97.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(pred,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "confident-arrest",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'C:/Users/Yashvi/Desktop/Model1.pth'\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "higher-complex",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=25, out_features=50, bias=True)\n",
       "  (drop1): Dropout(p=0.2, inplace=False)\n",
       "  (fc2): Linear(in_features=50, out_features=100, bias=True)\n",
       "  (fc3): Linear(in_features=100, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net()\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternative-marijuana",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
